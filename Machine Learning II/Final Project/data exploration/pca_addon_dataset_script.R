# Rattle is Copyright (c) 2006-2015 Togaware Pty Ltd.

#============================================================
# Rattle timestamp: 2017-04-18 16:29:48 x86_64-w64-mingw32 

# Rattle version 4.1.0 user 'VJ'

# This log file captures all Rattle interactions as R commands. 

Export this log to a file using the Export button or the Tools 
# menu to save a log of all your activity. This facilitates repeatability. For example, exporting 
# to a file called 'myrf01.R' will allow you to type in the R Console 
# the command source('myrf01.R') and so repeat all actions automatically. 
# Generally, you will want to edit the file to suit your needs. You can also directly 
# edit this current log in place to record additional information before exporting. 
 
# Saving and loading projects also retains this log.

# We begin by loading the required libraries.

library(rattle)   # To access the weather dataset and utility commands.
library(magrittr) # For the %>% and %<>% operators.

# This log generally records the process of building a model. However, with very 
# little effort the log can be used to score a new dataset. The logical variable 
# 'building' is used to toggle between generating transformations, as when building 
# a model, and simply using the transformations, as when scoring a dataset.

building <- TRUE
scoring  <- ! building


# A pre-defined value is used to reset the random seed so that results are repeatable.

crv$seed <- 42 

#============================================================
# Rattle timestamp: 2017-04-18 16:29:59 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/Copy of speeddating_April_13_with_avg.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 16:30:01 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- "pair_id"
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:30:07 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- NULL

crs$numeric <- NULL

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:33:51 x86_64-w64-mingw32 

# Remap variables. 

# Transform into a factor.

  crs$dataset[["TFC_f_race"]] <- as.factor(crs$dataset[["f_race"]])

  ol <- levels(crs$dataset[["TFC_f_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_race"]]) <- nl

#============================================================
# Rattle timestamp: 2017-04-18 16:33:52 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- "TFC_f_race"

crs$numeric <- NULL

crs$categoric <- "TFC_f_race"

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:34:12 x86_64-w64-mingw32 

# Remap variables. 

# Turn a factor into indicator variables.

  crs$dataset[, make.names(paste("TIN_TFC_f_race_", levels(crs$dataset[["TFC_f_race"]]), sep=""))] <- diag(nlevels(crs$dataset[["TFC_f_race"]]))[crs$dataset[["TFC_f_race"]],]

#============================================================
# Rattle timestamp: 2017-04-18 16:34:13 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- NULL

crs$numeric <- NULL

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_f_race")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:34:53 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.", "TIN_TFC_f_race_.3.4.",
     "TIN_TFC_f_race_.4.6.")

crs$numeric <- c("TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.", "TIN_TFC_f_race_.3.4.",
     "TIN_TFC_f_race_.4.6.")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_f_race")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:34:57 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- prcomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
axis(1, at=seq(0.7, ncol(pc$rotation)*1.2, 1.2), labels=colnames(pc$rotation), lty=0)

# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 16:35:57 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.",
     "TIN_TFC_f_race_.3.4.", "TIN_TFC_f_race_.4.6.")

crs$numeric <- c("f_avg_attr", "TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.",
     "TIN_TFC_f_race_.3.4.", "TIN_TFC_f_race_.4.6.")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_f_race")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:36:03 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- prcomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
axis(1, at=seq(0.7, ncol(pc$rotation)*1.2, 1.2), labels=colnames(pc$rotation), lty=0)

# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 16:38:47 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_avg_attr")

crs$numeric <- c("f_age", "f_avg_attr")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- "female_id"
crs$ignore  <- c("pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_f_race", "TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.", "TIN_TFC_f_race_.3.4.", "TIN_TFC_f_race_.4.6.")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:38:54 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- prcomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
axis(1, at=seq(0.7, ncol(pc$rotation)*1.2, 1.2), labels=colnames(pc$rotation), lty=0)

# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 16:40:08 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_imp_race", "f_imp_relig")

crs$numeric <- c("f_imp_race", "f_imp_relig")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- "female_id"
crs$ignore  <- c("pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_f_race", "TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.", "TIN_TFC_f_race_.3.4.", "TIN_TFC_f_race_.4.6.")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:40:19 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- prcomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
axis(1, at=seq(0.7, ncol(pc$rotation)*1.2, 1.2), labels=colnames(pc$rotation), lty=0)

# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 16:40:43 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- "female_id"
crs$ignore  <- c("pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_f_race", "TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.", "TIN_TFC_f_race_.3.4.", "TIN_TFC_f_race_.4.6.")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:40:51 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- prcomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
axis(1, at=seq(0.7, ncol(pc$rotation)*1.2, 1.2), labels=colnames(pc$rotation), lty=0)

# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 16:41:00 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- princomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))


# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 16:41:56 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun",
     "f_pref_amb")

crs$numeric <- c("f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun",
     "f_pref_amb")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- "female_id"
crs$ignore  <- c("pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_f_race", "TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.", "TIN_TFC_f_race_.3.4.", "TIN_TFC_f_race_.4.6.")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:43:27 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun",
     "f_pref_amb")

crs$numeric <- c("f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun",
     "f_pref_amb")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- "female_id"
crs$ignore  <- c("pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_f_race", "TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.", "TIN_TFC_f_race_.3.4.", "TIN_TFC_f_race_.4.6.")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:43:37 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- princomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))


# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 16:45:02 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- "female_id"
crs$ignore  <- c("pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_f_race", "TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.", "TIN_TFC_f_race_.3.4.", "TIN_TFC_f_race_.4.6.")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:45:35 x86_64-w64-mingw32 

# Transform variables by rescaling. 

# The 'reshape' package provides the 'rescaler' function.

library(reshape, quietly=TRUE)

# Rescale f_age.

crs$dataset[["R01_f_age"]] <- crs$dataset[["f_age"]]

# Rescale to [0,1].

if (building)
{
  crs$dataset[["R01_f_age"]] <-  rescaler(crs$dataset[["f_age"]], "range")
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["R01_f_age"]] <- (crs$dataset[["f_age"]] - 19.000000)/abs(55.000000 - 19.000000)
}

# Rescale f_imp_race.

crs$dataset[["R01_f_imp_race"]] <- crs$dataset[["f_imp_race"]]

# Rescale to [0,1].

if (building)
{
  crs$dataset[["R01_f_imp_race"]] <-  rescaler(crs$dataset[["f_imp_race"]], "range")
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["R01_f_imp_race"]] <- (crs$dataset[["f_imp_race"]] - 0.000000)/abs(10.000000 - 0.000000)
}

# Rescale f_imp_relig.

crs$dataset[["R01_f_imp_relig"]] <- crs$dataset[["f_imp_relig"]]

# Rescale to [0,1].

if (building)
{
  crs$dataset[["R01_f_imp_relig"]] <-  rescaler(crs$dataset[["f_imp_relig"]], "range")
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["R01_f_imp_relig"]] <- (crs$dataset[["f_imp_relig"]] - 1.000000)/abs(10.000000 - 1.000000)
}

#============================================================
# Rattle timestamp: 2017-04-18 16:45:36 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("R01_f_age", "R01_f_imp_race", "R01_f_imp_relig")

crs$numeric <- c("R01_f_age", "R01_f_imp_race", "R01_f_imp_relig")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- "female_id"
crs$ignore  <- c("pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_f_race", "TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.", "TIN_TFC_f_race_.3.4.", "TIN_TFC_f_race_.4.6.")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:45:45 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- princomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))


# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 16:45:58 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- prcomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
axis(1, at=seq(0.7, ncol(pc$rotation)*1.2, 1.2), labels=colnames(pc$rotation), lty=0)

# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 16:47:18 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like")

crs$numeric <- c("m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- "pair_id"
crs$ignore  <- c("order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "TFC_f_race", "TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.", "TIN_TFC_f_race_.3.4.", "TIN_TFC_f_race_.4.6.", "R01_f_age", "R01_f_imp_race", "R01_f_imp_relig")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:47:22 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- prcomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
axis(1, at=seq(0.7, ncol(pc$rotation)*1.2, 1.2), labels=colnames(pc$rotation), lty=0)

# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 16:48:05 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("female_dec", "male_dec")

crs$numeric <- c("female_dec", "male_dec")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- "pair_id"
crs$ignore  <- c("order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_f_race", "TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.", "TIN_TFC_f_race_.3.4.", "TIN_TFC_f_race_.4.6.", "R01_f_age", "R01_f_imp_race", "R01_f_imp_relig")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:48:07 x86_64-w64-mingw32 

# The 'Hmisc' package provides the 'contents' function.

library(Hmisc, quietly=TRUE)

# Obtain a summary of the dataset.

contents(crs$dataset[crs$sample, c(crs$input, crs$risk, crs$target)])
summary(crs$dataset[crs$sample, c(crs$input, crs$risk, crs$target)])

#============================================================
# Rattle timestamp: 2017-04-18 16:48:15 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- prcomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
axis(1, at=seq(0.7, ncol(pc$rotation)*1.2, 1.2), labels=colnames(pc$rotation), lty=0)

# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 16:48:59 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- "female_dec"

crs$numeric <- "female_dec"

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- "pair_id"
crs$ignore  <- c("order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_f_race", "TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.", "TIN_TFC_f_race_.3.4.", "TIN_TFC_f_race_.4.6.", "R01_f_age", "R01_f_imp_race", "R01_f_imp_relig")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:49:11 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("female_dec", "f_age", "f_imp_race", "f_imp_relig")

crs$numeric <- c("female_dec", "f_age", "f_imp_race", "f_imp_relig")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- "pair_id"
crs$ignore  <- c("order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_f_race", "TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.", "TIN_TFC_f_race_.3.4.", "TIN_TFC_f_race_.4.6.", "R01_f_age", "R01_f_imp_race", "R01_f_imp_relig")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:49:23 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("female_dec", "male_dec", "f_age", "f_imp_race",
     "f_imp_relig")

crs$numeric <- c("female_dec", "male_dec", "f_age", "f_imp_race",
     "f_imp_relig")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- "pair_id"
crs$ignore  <- c("order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_f_race", "TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.", "TIN_TFC_f_race_.3.4.", "TIN_TFC_f_race_.4.6.", "R01_f_age", "R01_f_imp_race", "R01_f_imp_relig")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:49:32 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- prcomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
axis(1, at=seq(0.7, ncol(pc$rotation)*1.2, 1.2), labels=colnames(pc$rotation), lty=0)

# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 16:50:05 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- "pair_id"
crs$ignore  <- c("order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_f_race", "TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.", "TIN_TFC_f_race_.3.4.", "TIN_TFC_f_race_.4.6.", "R01_f_age", "R01_f_imp_race", "R01_f_imp_relig")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:50:54 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun",
     "f_pref_amb")

crs$numeric <- c("f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun",
     "f_pref_amb")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- "pair_id"
crs$ignore  <- c("order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_f_race", "TIN_TFC_f_race_.1.1.", "TIN_TFC_f_race_.1.2.", "TIN_TFC_f_race_.2.3.", "TIN_TFC_f_race_.3.4.", "TIN_TFC_f_race_.4.6.", "R01_f_age", "R01_f_imp_race", "R01_f_imp_relig")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 16:55:23 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- prcomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
axis(1, at=seq(0.7, ncol(pc$rotation)*1.2, 1.2), labels=colnames(pc$rotation), lty=0)

# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components Copy of speeddating_April_13_with_avg.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 17:04:40 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_addon_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 17:04:41 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:05:20 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("m_avg_attr", "m_avg_intel", "f_pref_pca_vec_1", "f_pref_pca_vec_2")

crs$numeric <- c("m_avg_attr", "m_avg_intel", "f_pref_pca_vec_1", "f_pref_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_sinc", "m_avg_fun", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:05:23 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.02 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:05:39 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2")

crs$numeric <- c("m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:05:43 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.02 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:05:47 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:06:20 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("samerace", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2")

crs$numeric <- c("samerace", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:06:24 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.02 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:07:06 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("samerace", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2")

crs$numeric <- c("samerace", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:07:08 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.02 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:07:37 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("samerace", "f_age", "m_age", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2")

crs$numeric <- c("samerace", "f_age", "m_age", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:07:40 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.03 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:07:45 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(match) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 1.64 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:07:49 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:09:10 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "samerace", "f_age", "f_imp_race",
     "f_imp_relig", "m_age", "m_imp_race", "m_imp_relig",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2")

crs$numeric <- c("interest_corr", "samerace", "f_age", "f_imp_race",
     "f_imp_relig", "m_age", "m_imp_race", "m_imp_relig",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:09:14 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.02 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:10:03 x86_64-w64-mingw32 

# Remap variables. 

# Transform into a factor.

  crs$dataset[["TFC_samerace"]] <- as.factor(crs$dataset[["samerace"]])
  crs$dataset[["TFC_f_race"]] <- as.factor(crs$dataset[["f_race"]])
  crs$dataset[["TFC_m_race"]] <- as.factor(crs$dataset[["m_race"]])

  ol <- levels(crs$dataset[["TFC_samerace"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_samerace"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_race"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_race"]]) <- nl

#============================================================
# Rattle timestamp: 2017-04-18 17:10:04 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("interest_corr", "f_age", "f_imp_race", "f_imp_relig",
     "m_age", "m_imp_race", "m_imp_relig", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$numeric <- c("interest_corr", "f_age", "f_imp_race", "f_imp_relig",
     "m_age", "m_imp_race", "m_imp_relig", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:10:14 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "f_age", "f_imp_race", "f_imp_relig",
     "m_age", "m_imp_race", "m_imp_relig", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$numeric <- c("interest_corr", "f_age", "f_imp_race", "f_imp_relig",
     "m_age", "m_imp_race", "m_imp_relig", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:10:17 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.02 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:10:23 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(match) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 2.04 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:10:49 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "f_age", "f_imp_race", "f_imp_relig",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "TFC_samerace",
     "TFC_f_race", "TFC_m_race")

crs$numeric <- c("interest_corr", "f_age", "f_imp_race", "f_imp_relig",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:10:59 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.03 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:11:02 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(match) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 1.98 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:11:41 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("m_rate_self_attr", "m_avg_attr")

crs$numeric <- c("m_rate_self_attr", "m_avg_attr")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_m_race")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:12:03 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("m_rate_self_attr", "m_avg_attr")

crs$numeric <- c("m_rate_self_attr", "m_avg_attr")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- "male_id"
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_m_race")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:12:06 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- prcomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
axis(1, at=seq(0.7, ncol(pc$rotation)*1.2, 1.2), labels=colnames(pc$rotation), lty=0)

# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 17:13:11 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("m_rate_self_attr", "m_rate_self_intel", "m_avg_attr", "m_avg_intel")

crs$numeric <- c("m_rate_self_attr", "m_rate_self_intel", "m_avg_attr", "m_avg_intel")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- "male_id"
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_amb", "m_avg_sinc", "m_avg_fun", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_m_race")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:13:15 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- prcomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
axis(1, at=seq(0.7, ncol(pc$rotation)*1.2, 1.2), labels=colnames(pc$rotation), lty=0)

# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 17:13:28 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- princomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))


# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 17:14:40 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("female_dec", "m_rate_self_attr", "m_rate_self_intel", "m_avg_attr",
     "m_avg_intel")

crs$numeric <- c("female_dec", "m_rate_self_attr", "m_rate_self_intel", "m_avg_attr",
     "m_avg_intel")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- "male_id"
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_amb", "m_avg_sinc", "m_avg_fun", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_m_race")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:14:43 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- princomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))


# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 17:18:54 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "f_age", "f_field", "f_field_num",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_age", "m_field",
     "m_field_num", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_samerace",
     "TFC_f_race", "TFC_m_race")

crs$numeric <- c("interest_corr", "f_age", "f_field_num", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_field_num", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career",
     "TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_race", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_race", "f_pref_pca_vec_1", "f_pref_pca_vec_2")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:19:02 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.60 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:19:16 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:19:42 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(female_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 6.97 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:20:01 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:22:45 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_imp_race", "f_imp_relig", "m_age", "m_field",
     "m_field_num", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$numeric <- c("f_imp_race", "f_imp_relig", "m_age", "m_field_num",
     "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq",
     "m_out_freq", "m_career_num", "m_like_sports", "m_like_tvsports",
     "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art",
     "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading",
     "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts",
     "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy",
     "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun",
     "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc",
     "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar",
     "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun",
     "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc",
     "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2")

crs$categoric <- c("m_field", "m_career", "TFC_samerace", "TFC_f_race",
     "TFC_m_race")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_race")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:22:49 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.34 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:22:53 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:23:01 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(female_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 3.56 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:23:08 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:24:28 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "f_imp_race", "f_imp_relig", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "TFC_samerace", "TFC_f_race",
     "TFC_m_race")

crs$numeric <- c("interest_corr", "f_imp_race", "f_imp_relig", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:24:31 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.13 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:24:43 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 17:25:20 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:25:40 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=10,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.15 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:25:47 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=10,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.14 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:25:51 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=10,
           minbucket=4,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.14 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:25:55 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:26:04 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.010000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=50)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 4.45 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:26:13 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:26:24 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.010000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=120)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 11.53 secs

# Display tree number 1.

drawTreesAda(crs$ada, 1, ": pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 17:31:57 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "f_imp_race", "f_imp_relig", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "TFC_samerace",
     "TFC_f_race", "TFC_m_race")

crs$numeric <- c("interest_corr", "f_imp_race", "f_imp_relig", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:31:59 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=10,
           minbucket=4,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.19 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:32:12 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:33:18 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_pref_attr", "f_genderpref_attr")

crs$numeric <- c("f_pref_attr", "f_genderpref_attr")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_m_race")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:33:21 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- princomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))


# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 17:36:44 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun",
     "f_oppgender_pref_amb")

crs$numeric <- c("f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun",
     "f_oppgender_pref_amb")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- "female_id"
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_m_race")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:36:48 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- princomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))


# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 17:46:33 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_match_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 17:46:35 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:46:39 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_addon_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 17:46:41 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

#============================================================
# Rattle timestamp: 2017-04-18 17:47:12 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "samerace", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2")

crs$numeric <- c("interest_corr", "samerace", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:47:50 x86_64-w64-mingw32 

# Remap variables. 

# Transform into a factor.

  crs$dataset[["TFC_samerace"]] <- as.factor(crs$dataset[["samerace"]])
  crs$dataset[["TFC_f_race"]] <- as.factor(crs$dataset[["f_race"]])
  crs$dataset[["TFC_m_race"]] <- as.factor(crs$dataset[["m_race"]])

  ol <- levels(crs$dataset[["TFC_samerace"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_samerace"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_race"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_race"]]) <- nl

#============================================================
# Rattle timestamp: 2017-04-18 17:47:51 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("interest_corr", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$numeric <- c("interest_corr", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:48:48 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "TFC_samerace",
     "TFC_f_race", "TFC_m_race")

crs$numeric <- c("interest_corr", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:48:52 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.14 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:48:55 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 17:49:24 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:49:40 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:50:00 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "TFC_samerace",
     "TFC_f_race", "TFC_m_race")

crs$numeric <- c("interest_corr", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:50:03 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.03 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:50:10 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:50:49 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "TFC_samerace",
     "TFC_f_race", "TFC_m_race")

crs$numeric <- c("interest_corr", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:50:54 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.15 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:51:06 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:52:50 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "f_imp_race", "f_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$numeric <- c("interest_corr", "f_imp_race", "f_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:52:55 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.15 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:53:01 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 17:53:19 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minbucket=3,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.16 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:53:26 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=5,
           minbucket=3,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.16 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:53:34 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=5,
           minbucket=3,
           maxdepth=3,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.06 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:53:52 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=5,
           minbucket=3,
           cp=1.000000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.02 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:54:01 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=5,
           minbucket=3,
           cp=0.000500,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.28 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:54:08 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 17:54:29 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=5,
           minbucket=3,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.18 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:54:33 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 17:54:42 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 17:54:44 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=5,
           minbucket=3,
           cp=0.001000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.27 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:54:46 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 17:54:58 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=5,
           minbucket=3,
           cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.22 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:55:00 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 17:55:13 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:55:26 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:55:30 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset, type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:56:00 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "f_age", "f_imp_race", "f_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "TFC_samerace", "TFC_f_race",
     "TFC_m_race")

crs$numeric <- c("interest_corr", "f_age", "f_imp_race", "f_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_m_race")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:56:24 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=15,
           minbucket=20,
           cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.14 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:56:31 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 17:56:36 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:58:34 x86_64-w64-mingw32 

# Remap variables. 

# Transform into a factor.

  crs$dataset[["TFC_f_goal"]] <- as.factor(crs$dataset[["f_goal"]])
  crs$dataset[["TFC_f_dat_freq"]] <- as.factor(crs$dataset[["f_dat_freq"]])
  crs$dataset[["TFC_f_out_freq"]] <- as.factor(crs$dataset[["f_out_freq"]])

  ol <- levels(crs$dataset[["TFC_f_goal"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_goal"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_dat_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_dat_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_out_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_out_freq"]]) <- nl

#============================================================
# Rattle timestamp: 2017-04-18 17:58:35 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("interest_corr", "f_age", "f_imp_race", "f_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "TFC_samerace", "TFC_f_race",
     "TFC_m_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq")

crs$numeric <- c("interest_corr", "f_age", "f_imp_race", "f_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_m_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 17:58:49 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=15,
           minbucket=20,
           cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.16 secs

#============================================================
# Rattle timestamp: 2017-04-18 17:58:56 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:59:00 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 17:59:04 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 18:00:48 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "f_age", "f_imp_race", "f_imp_relig",
     "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel",
     "f_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "TFC_samerace",
     "TFC_f_race", "TFC_m_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq")

crs$numeric <- c("interest_corr", "f_age", "f_imp_race", "f_imp_relig",
     "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel",
     "f_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_m_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:00:53 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=15,
           minbucket=20,
           cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.18 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:00:57 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 18:02:14 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel",
     "f_rate_self_amb")

crs$numeric <- c("f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel",
     "f_rate_self_amb")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_m_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:02:20 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- princomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))


# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 18:05:16 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_match_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 18:05:18 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:05:20 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_addon_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 18:05:22 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:06:00 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2")

crs$numeric <- c("f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- "female_dec"
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:06:14 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2")

crs$numeric <- c("f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:06:16 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.06 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:06:23 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:06:32 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 18:08:36 x86_64-w64-mingw32 

# Remap variables. 

# Transform into a factor.

  crs$dataset[["TFC_samerace"]] <- as.factor(crs$dataset[["samerace"]])
  crs$dataset[["TFC_f_race"]] <- as.factor(crs$dataset[["f_race"]])
  crs$dataset[["TFC_f_goal"]] <- as.factor(crs$dataset[["f_goal"]])
  crs$dataset[["TFC_f_dat_freq"]] <- as.factor(crs$dataset[["f_dat_freq"]])
  crs$dataset[["TFC_f_out_freq"]] <- as.factor(crs$dataset[["f_out_freq"]])

  ol <- levels(crs$dataset[["TFC_samerace"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_samerace"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_race"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_goal"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_goal"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_dat_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_dat_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_out_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_out_freq"]]) <- nl

#============================================================
# Rattle timestamp: 2017-04-18 18:08:37 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "TFC_samerace", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq")

crs$numeric <- c("f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:09:04 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.08 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:09:07 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.08 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:10:48 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:10:51 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.09 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:10:56 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 18:11:06 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.11 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:11:08 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 18:12:08 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:12:13 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:12:20 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.010000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=120)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 8.98 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:13:14 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:13:19 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:13:23 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset, type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset)

# Generate the confusion matrix showing counts.

table(crs$dataset$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:13:49 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "TFC_samerace",
     "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:13:55 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.15 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:13:59 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 18:15:38 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:15:46 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.010000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=120)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 12.01 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:16:02 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:17:34 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "f_age", "f_imp_race", "f_imp_relig",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "TFC_samerace", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq")

crs$numeric <- c("interest_corr", "f_age", "f_imp_race", "f_imp_relig",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:22:11 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2")

crs$categoric <- c("TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_samerace")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:22:14 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.14 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:22:20 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 18:22:49 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:22:54 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:23:26 x86_64-w64-mingw32 

# Remap variables. 

# Transform into a factor.

  crs$dataset[["TFC_f_field_num"]] <- as.factor(crs$dataset[["f_field_num"]])

  ol <- levels(crs$dataset[["TFC_f_field_num"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_field_num"]]) <- nl

#============================================================
# Rattle timestamp: 2017-04-18 18:23:27 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_f_field_num")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2")

crs$categoric <- c("TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq",
     "TFC_f_field_num")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "TFC_samerace")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:23:38 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.14 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:23:47 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 18:24:48 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=15,
           cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.14 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:24:52 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:24:57 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:25:11 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "TFC_samerace",
     "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq",
     "TFC_f_field_num")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_f_field_num")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:25:18 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=15,
           cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.16 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:25:21 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 18:25:58 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.010000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=120)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 12.18 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:26:33 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:26:38 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:27:53 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_f_field_num")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_f_field_num")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:27:56 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=15,
           cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.29 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:27:58 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 18:29:11 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:29:14 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:29:20 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.010000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=120)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 15.66 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:29:41 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:29:45 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:32:15 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "f_age", "f_imp_race", "f_imp_relig",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "TFC_samerace", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_f_field_num")

crs$numeric <- c("interest_corr", "f_age", "f_imp_race", "f_imp_relig",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_f_field_num")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:32:21 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=15,
           cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.31 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:32:25 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 18:32:36 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:32:41 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:32:55 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "samerace", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "TFC_samerace",
     "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq",
     "TFC_f_field_num")

crs$numeric <- c("interest_corr", "samerace", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_f_field_num")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:32:59 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=15,
           cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.31 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:33:01 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 18:38:14 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining",
     "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming",
     "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater",
     "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping",
     "f_like_yoga")

crs$numeric <- c("f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining",
     "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming",
     "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater",
     "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping",
     "f_like_yoga")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_f_field_num")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:38:18 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- princomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))


# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 18:40:09 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga")

crs$numeric <- c("m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_f_field_num")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:40:14 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- princomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))


# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 18:42:45 x86_64-w64-mingw32 

# Perform missing value imputation. 

#============================================================
# Rattle timestamp: 2017-04-18 18:42:45 x86_64-w64-mingw32 

# Transform variables by imputing missing values. 

# Impute m_pref_fun.

crs$dataset[["IMD_m_pref_fun"]] <- crs$dataset[["m_pref_fun"]]

# Change all NAs to the median (not advisable).

if (building)
{
  crs$dataset[["IMD_m_pref_fun"]][is.na(crs$dataset[["m_pref_fun"]])] <- median(crs$dataset[["m_pref_fun"]], na.rm=TRUE)
}

# When scoring, transform using the training data parameters:

if (scoring)
{
  crs$dataset[["IMD_m_pref_fun"]][is.na(crs$dataset[["m_pref_fun"]])] <- 18.75
}

# Impute m_pref_amb.

crs$dataset[["IMD_m_pref_amb"]] <- crs$dataset[["m_pref_amb"]]

# Change all NAs to the median (not advisable).

if (building)
{
  crs$dataset[["IMD_m_pref_amb"]][is.na(crs$dataset[["m_pref_amb"]])] <- median(crs$dataset[["m_pref_amb"]], na.rm=TRUE)
}

# When scoring, transform using the training data parameters:

if (scoring)
{
  crs$dataset[["IMD_m_pref_amb"]][is.na(crs$dataset[["m_pref_amb"]])] <- 10
}

#============================================================
# Rattle timestamp: 2017-04-18 18:42:46 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("IMD_m_pref_fun", "IMD_m_pref_amb")

crs$numeric <- c("IMD_m_pref_fun", "IMD_m_pref_amb")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_f_field_num")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:43:22 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("m_pref_attr", "m_pref_sinc", "m_pref_intel", "IMD_m_pref_fun",
     "IMD_m_pref_amb")

crs$numeric <- c("m_pref_attr", "m_pref_sinc", "m_pref_intel", "IMD_m_pref_fun",
     "IMD_m_pref_amb")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "TFC_samerace", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_f_field_num")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:43:30 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- princomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))


# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 18:54:28 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_match_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 18:54:30 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:54:32 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_addon_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 18:54:34 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:55:56 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_match_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 18:55:58 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:56:00 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_addon_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 18:56:02 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:56:22 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_pref_pca_vec_1", "f_pref_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$numeric <- c("f_pref_pca_vec_1", "f_pref_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:56:29 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.07 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:56:40 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:58:08 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:58:13 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.12 secs

#============================================================
# Rattle timestamp: 2017-04-18 18:58:15 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 18:58:49 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 18:59:02 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 18:59:06 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.02 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:00:18 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("female_dec", "male_dec", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$numeric <- c("female_dec", "male_dec", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:00:21 x86_64-w64-mingw32 

# The 'Hmisc' package provides the 'describe' function.

library(Hmisc, quietly=TRUE)

# Generate a description of the dataset.

describe(crs$dataset[crs$sample, c(crs$input, crs$risk, crs$target)])

#============================================================
# Rattle timestamp: 2017-04-18 19:01:47 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:01:50 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.03 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:02:08 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:02:10 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.16 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:02:13 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 19:03:40 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:03:46 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.24 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:03:47 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 19:04:18 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.30 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:04:19 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 19:04:33 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:04:40 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:05:01 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:05:05 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.26 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:05:07 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 19:05:27 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:05:35 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:05:47 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.010000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=120)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 13.01 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:06:05 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:06:15 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(match) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 1.80 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:06:21 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:06:44 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 28.66 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:07:16 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:07:25 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:09:42 x86_64-w64-mingw32 

# Remap variables. 

# Transform into a factor.

  crs$dataset[["TFC_samerace"]] <- as.factor(crs$dataset[["samerace"]])
  crs$dataset[["TFC_f_field_num"]] <- as.factor(crs$dataset[["f_field_num"]])
  crs$dataset[["TFC_f_race"]] <- as.factor(crs$dataset[["f_race"]])
  crs$dataset[["TFC_f_goal"]] <- as.factor(crs$dataset[["f_goal"]])
  crs$dataset[["TFC_f_dat_freq"]] <- as.factor(crs$dataset[["f_dat_freq"]])
  crs$dataset[["TFC_f_out_freq"]] <- as.factor(crs$dataset[["f_out_freq"]])
  crs$dataset[["TFC_m_race"]] <- as.factor(crs$dataset[["m_race"]])
  crs$dataset[["TFC_m_goal"]] <- as.factor(crs$dataset[["m_goal"]])
  crs$dataset[["TFC_m_out_freq"]] <- as.factor(crs$dataset[["m_out_freq"]])

  ol <- levels(crs$dataset[["TFC_samerace"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_samerace"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_field_num"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_field_num"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_race"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_goal"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_goal"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_dat_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_dat_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_out_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_out_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_race"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_goal"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_goal"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_out_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_out_freq"]]) <- nl

#============================================================
# Rattle timestamp: 2017-04-18 19:09:43 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:10:24 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_age", "m_imp_race", "m_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "TFC_samerace", "TFC_f_field_num",
     "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq",
     "TFC_m_race", "TFC_m_goal", "TFC_m_out_freq")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_age", "m_imp_race", "m_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:10:30 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.34 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:10:32 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 19:11:03 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:11:30 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 40.08 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:12:18 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:12:31 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:13:03 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.1*crs$nobs) # 410 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1643 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_age", "m_imp_race", "m_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "TFC_samerace", "TFC_f_field_num",
     "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq",
     "TFC_m_race", "TFC_m_goal", "TFC_m_out_freq")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_age", "m_imp_race", "m_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:13:09 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.25 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:13:12 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 19:13:26 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 28.18 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:14:19 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:14:26 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:16:51 x86_64-w64-mingw32 

# Transform variables by rescaling. 

# The 'reshape' package provides the 'rescaler' function.

library(reshape, quietly=TRUE)

# Rescale f_age.

crs$dataset[["R01_f_age"]] <- crs$dataset[["f_age"]]

# Rescale to [0,1].

if (building)
{
  crs$dataset[["R01_f_age"]] <-  rescaler(crs$dataset[["f_age"]], "range")
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["R01_f_age"]] <- (crs$dataset[["f_age"]] - 19.000000)/abs(55.000000 - 19.000000)
}

# Rescale f_imp_race.

crs$dataset[["R01_f_imp_race"]] <- crs$dataset[["f_imp_race"]]

# Rescale to [0,1].

if (building)
{
  crs$dataset[["R01_f_imp_race"]] <-  rescaler(crs$dataset[["f_imp_race"]], "range")
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["R01_f_imp_race"]] <- (crs$dataset[["f_imp_race"]] - 0.000000)/abs(10.000000 - 0.000000)
}

# Rescale f_imp_relig.

crs$dataset[["R01_f_imp_relig"]] <- crs$dataset[["f_imp_relig"]]

# Rescale to [0,1].

if (building)
{
  crs$dataset[["R01_f_imp_relig"]] <-  rescaler(crs$dataset[["f_imp_relig"]], "range")
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["R01_f_imp_relig"]] <- (crs$dataset[["f_imp_relig"]] - 1.000000)/abs(10.000000 - 1.000000)
}

#============================================================
# Rattle timestamp: 2017-04-18 19:16:52 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_age", "m_imp_race",
     "m_imp_relig", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "TFC_samerace",
     "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal", "TFC_m_out_freq",
     "R01_f_age", "R01_f_imp_race", "R01_f_imp_relig")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_age", "m_imp_race",
     "m_imp_relig", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "R01_f_age",
     "R01_f_imp_race", "R01_f_imp_relig")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:17:11 x86_64-w64-mingw32 

# Transform variables by rescaling. 

# The 'reshape' package provides the 'rescaler' function.

library(reshape, quietly=TRUE)

# Rescale m_age.

crs$dataset[["R01_m_age"]] <- crs$dataset[["m_age"]]

# Rescale to [0,1].

if (building)
{
  crs$dataset[["R01_m_age"]] <-  rescaler(crs$dataset[["m_age"]], "range")
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["R01_m_age"]] <- (crs$dataset[["m_age"]] - 18.000000)/abs(42.000000 - 18.000000)
}

# Rescale m_imp_race.

crs$dataset[["R01_m_imp_race"]] <- crs$dataset[["m_imp_race"]]

# Rescale to [0,1].

if (building)
{
  crs$dataset[["R01_m_imp_race"]] <-  rescaler(crs$dataset[["m_imp_race"]], "range")
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["R01_m_imp_race"]] <- (crs$dataset[["m_imp_race"]] - 1.000000)/abs(10.000000 - 1.000000)
}

# Rescale m_imp_relig.

crs$dataset[["R01_m_imp_relig"]] <- crs$dataset[["m_imp_relig"]]

# Rescale to [0,1].

if (building)
{
  crs$dataset[["R01_m_imp_relig"]] <-  rescaler(crs$dataset[["m_imp_relig"]], "range")
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["R01_m_imp_relig"]] <- (crs$dataset[["m_imp_relig"]] - 1.000000)/abs(10.000000 - 1.000000)
}

#============================================================
# Rattle timestamp: 2017-04-18 19:17:12 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq", "R01_f_age", "R01_f_imp_race", "R01_f_imp_relig",
     "R01_m_age", "R01_m_imp_race", "R01_m_imp_relig")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "R01_f_age", "R01_f_imp_race", "R01_f_imp_relig", "R01_m_age",
     "R01_m_imp_race", "R01_m_imp_relig")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:17:32 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.26 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:17:34 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 19:17:46 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

#============================================================
# Rattle timestamp: 2017-04-18 19:17:54 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

#============================================================
# Rattle timestamp: 2017-04-18 19:19:00 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(match) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=500,
      mtry=5,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 6.20 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:19:20 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:19:34 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:19:56 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(match) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=700,
      mtry=7,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 8.26 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:20:15 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 28.15 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:21:01 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:21:08 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:22:04 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.1*crs$nobs) # 410 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1643 observations

# The following variable selections have been noted.

crs$input <- c("f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining",
     "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming",
     "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater",
     "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping",
     "f_like_yoga", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_like_sports",
     "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums",
     "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing",
     "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies",
     "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "TFC_samerace", "TFC_f_field_num",
     "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq",
     "TFC_m_race", "TFC_m_goal", "TFC_m_out_freq", "R01_f_age",
     "R01_f_imp_race", "R01_f_imp_relig", "R01_m_age", "R01_m_imp_race",
     "R01_m_imp_relig")

crs$numeric <- c("f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining",
     "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming",
     "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater",
     "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping",
     "f_like_yoga", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_like_sports",
     "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums",
     "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing",
     "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies",
     "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "R01_f_age", "R01_f_imp_race",
     "R01_f_imp_relig", "R01_m_age", "R01_m_imp_race", "R01_m_imp_relig")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:22:11 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.37 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:22:15 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 19:22:36 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:22:47 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 1.00 mins

#============================================================
# Rattle timestamp: 2017-04-18 19:30:59 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:31:07 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:32:12 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.1*crs$nobs) # 410 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1643 observations

# The following variable selections have been noted.

crs$input <- c("interest_corr", "samerace", "f_like_sports", "f_like_tvsports",
     "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art",
     "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading",
     "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts",
     "f_like_music", "f_like_shopping", "f_like_yoga", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_like_sports", "m_like_tvsports", "m_like_exercise",
     "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking",
     "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv",
     "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music",
     "m_like_shopping", "m_like_yoga", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq", "R01_f_age", "R01_f_imp_race", "R01_f_imp_relig",
     "R01_m_age", "R01_m_imp_race", "R01_m_imp_relig")

crs$numeric <- c("interest_corr", "samerace", "f_like_sports", "f_like_tvsports",
     "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art",
     "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading",
     "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts",
     "f_like_music", "f_like_shopping", "f_like_yoga", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_like_sports", "m_like_tvsports", "m_like_exercise",
     "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking",
     "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv",
     "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music",
     "m_like_shopping", "m_like_yoga", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "R01_f_age", "R01_f_imp_race", "R01_f_imp_relig", "R01_m_age",
     "R01_m_imp_race", "R01_m_imp_relig")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:32:21 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.38 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:34:07 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.1*crs$nobs) # 410 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1643 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "samerace", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "TFC_samerace",
     "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal", "TFC_m_out_freq",
     "R01_f_age", "R01_f_imp_race", "R01_f_imp_relig", "R01_m_age",
     "R01_m_imp_race", "R01_m_imp_relig")

crs$numeric <- c("order", "interest_corr", "samerace", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "R01_f_age",
     "R01_f_imp_race", "R01_f_imp_relig", "R01_m_age", "R01_m_imp_race",
     "R01_m_imp_relig")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:34:13 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.25 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:34:17 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 19:34:27 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:34:38 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 30.78 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:36:10 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:36:27 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.1*crs$nobs) # 410 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1643 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "samerace", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "TFC_samerace",
     "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal", "TFC_m_out_freq",
     "R01_f_age", "R01_f_imp_race", "R01_f_imp_relig", "R01_m_age",
     "R01_m_imp_race", "R01_m_imp_relig")

crs$numeric <- c("order", "interest_corr", "samerace", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "R01_f_age",
     "R01_f_imp_race", "R01_f_imp_relig", "R01_m_age", "R01_m_imp_race",
     "R01_m_imp_relig")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:36:30 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.28 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:36:37 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:36:47 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 30.86 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:37:37 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:37:44 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:38:45 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.1*crs$nobs) # 410 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1643 observations

# The following variable selections have been noted.

crs$input <- NULL

crs$numeric <- NULL

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal", "TFC_m_out_freq", "R01_f_age", "R01_f_imp_race", "R01_f_imp_relig", "R01_m_age", "R01_m_imp_race", "R01_m_imp_relig")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:39:40 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_match_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 19:39:42 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:39:44 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_addon_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 19:39:46 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id", "samerace")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:40:23 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun",
     "m_opp_gender_pref_amb")

crs$numeric <- c("m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun",
     "m_opp_gender_pref_amb")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:40:27 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- princomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))


# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 19:44:14 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_match_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 19:44:16 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:44:21 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_addon_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 19:44:23 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:45:05 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2")

crs$numeric <- c("f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:45:09 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.15 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:45:24 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.17 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:45:26 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 19:46:06 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:46:19 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 19.47 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:48:49 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:48:57 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:49:11 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(female_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 2.22 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:49:17 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:49:37 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- NULL

crs$numeric <- NULL

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:50:16 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb")

crs$numeric <- c("m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:50:19 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- princomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))


# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 19:52:14 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_match_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 19:52:16 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:52:18 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_addon_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 19:52:20 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:53:01 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$numeric <- c("f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:53:04 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.19 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:53:13 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 19:53:16 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.21 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:53:19 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 19:53:43 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:53:47 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:54:08 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$numeric <- c("m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:54:17 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.25 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:54:20 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 19:54:32 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:54:38 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 19:54:58 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 19:55:01 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.32 secs

#============================================================
# Rattle timestamp: 2017-04-18 19:55:03 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 20:01:45 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:02:14 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:02:19 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("female_dec", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2")

crs$numeric <- c("female_dec", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 20:02:23 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.16 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:02:26 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 20:02:38 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:02:53 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:02:58 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.010000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 24.12 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:03:28 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:03:57 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 24.84 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:05:20 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:05:41 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

#============================================================
# Rattle timestamp: 2017-04-18 20:05:46 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 20:05:51 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 33.78 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:06:31 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:06:37 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:07:42 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$numeric <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 20:07:46 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.40 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:07:49 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 20:08:15 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:08:31 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "male_dec", "f_age",
     "f_imp_race", "f_imp_relig", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2")

crs$numeric <- c("order", "interest_corr", "male_dec", "f_age",
     "f_imp_race", "f_imp_relig", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 20:08:37 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.24 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:08:40 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 20:08:49 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:08:53 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:09:07 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "female_dec", "f_age",
     "f_imp_race", "f_imp_relig", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2")

crs$numeric <- c("order", "interest_corr", "female_dec", "f_age",
     "f_imp_race", "f_imp_relig", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 20:09:11 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.20 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:09:12 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 20:09:27 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:09:30 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:11:15 x86_64-w64-mingw32 

# Remap variables. 

# Transform into a factor.

  crs$dataset[["TFC_samerace"]] <- as.factor(crs$dataset[["samerace"]])
  crs$dataset[["TFC_f_field_num"]] <- as.factor(crs$dataset[["f_field_num"]])
  crs$dataset[["TFC_f_race"]] <- as.factor(crs$dataset[["f_race"]])
  crs$dataset[["TFC_f_goal"]] <- as.factor(crs$dataset[["f_goal"]])
  crs$dataset[["TFC_f_dat_freq"]] <- as.factor(crs$dataset[["f_dat_freq"]])
  crs$dataset[["TFC_f_out_freq"]] <- as.factor(crs$dataset[["f_out_freq"]])
  crs$dataset[["TFC_m_race"]] <- as.factor(crs$dataset[["m_race"]])
  crs$dataset[["TFC_m_goal"]] <- as.factor(crs$dataset[["m_goal"]])
  crs$dataset[["TFC_m_out_freq"]] <- as.factor(crs$dataset[["m_out_freq"]])

  ol <- levels(crs$dataset[["TFC_samerace"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_samerace"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_field_num"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_field_num"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_race"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_goal"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_goal"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_dat_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_dat_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_out_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_out_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_race"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_goal"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_goal"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_out_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_out_freq"]]) <- nl

#============================================================
# Rattle timestamp: 2017-04-18 20:11:16 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "female_dec", "f_age",
     "f_imp_race", "f_imp_relig", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "TFC_samerace", "TFC_f_field_num", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race",
     "TFC_m_goal", "TFC_m_out_freq")

crs$numeric <- c("order", "interest_corr", "female_dec", "f_age",
     "f_imp_race", "f_imp_relig", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 20:11:40 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.21 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:11:42 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 20:12:04 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$numeric <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 20:12:07 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.43 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:12:09 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 20:12:54 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:12:57 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:13:08 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 48.97 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:14:55 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:15:06 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:15:15 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:16:17 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(match) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=700,
      mtry=6,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 14.81 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:16:41 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:16:53 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:17:39 x86_64-w64-mingw32 

# Remap variables. 

# Transform into a factor.

  crs$dataset[["TFC_female_dec"]] <- as.factor(crs$dataset[["female_dec"]])

  ol <- levels(crs$dataset[["TFC_female_dec"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_female_dec"]]) <- nl

#============================================================
# Rattle timestamp: 2017-04-18 20:17:40 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq", "TFC_female_dec")

crs$numeric <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq", "TFC_female_dec")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 20:17:55 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq", "TFC_female_dec")

crs$numeric <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq", "TFC_female_dec")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 20:18:00 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.20 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:18:04 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 20:18:11 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:18:44 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=15,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 35.46 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:19:30 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:19:45 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:23:24 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.6*crs$nobs) # 2463 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1027 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$numeric <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "TFC_female_dec")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 20:23:27 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.36 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:23:29 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 20:24:11 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:24:20 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=15,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 41.44 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:26:59 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:27:10 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:27:20 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset, type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset)

# Generate the confusion matrix showing counts.

table(crs$dataset$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:28:07 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$numeric <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "TFC_female_dec")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 20:28:25 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=15,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 34.54 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:29:17 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:29:25 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:29:47 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "female_dec", "f_age",
     "f_imp_race", "f_imp_relig", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "TFC_samerace", "TFC_f_field_num", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race",
     "TFC_m_goal", "TFC_m_out_freq")

crs$numeric <- c("order", "interest_corr", "female_dec", "f_age",
     "f_imp_race", "f_imp_relig", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "TFC_female_dec")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 20:29:58 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.18 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:30:00 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 20:35:40 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.15 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:35:42 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 20:36:13 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:36:33 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$numeric <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "TFC_female_dec")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 20:36:57 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.32 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:36:59 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.34 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:37:03 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:37:16 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:37:20 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 20:38:02 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=15,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 35.92 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:39:30 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:41:37 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$numeric <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "TFC_female_dec")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 20:41:41 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.31 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:41:42 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-18 20:47:38 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:47:59 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(male_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=15,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 36.18 secs

#============================================================
# Rattle timestamp: 2017-04-18 20:49:22 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:50:20 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset, type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset)

# Generate the confusion matrix showing counts.

table(crs$dataset$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 20:54:58 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 21:04:47 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining",
     "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming",
     "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater",
     "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping",
     "f_like_yoga")

crs$numeric <- c("f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining",
     "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming",
     "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater",
     "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping",
     "f_like_yoga")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal", "TFC_m_out_freq", "TFC_female_dec")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 21:04:51 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- princomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))


# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 21:09:38 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga")

crs$numeric <- c("m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga")

crs$categoric <- NULL

crs$target  <- NULL
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal", "TFC_m_out_freq", "TFC_female_dec")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 21:09:45 x86_64-w64-mingw32 

# Principal Components Analysis (on numerics only).

pc <- princomp(na.omit(crs$dataset[crs$sample, crs$numeric]), scale=TRUE, center=TRUE, tol=0)

# Show the output of the analysis.

pc

# Summarise the importance of the components found.

summary(pc)

# Display a plot showing the relative importance of the components.

plot(pc, main="")
title(main="Principal Components Importance pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))


# Display a plot showing the two most principal components.

biplot(pc, main="")
title(main="Principal Components pca_addon_dataset.csv",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-18 21:10:39 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_match_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 21:10:42 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 21:13:25 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_addon_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 21:13:28 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 21:14:01 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$numeric <- c("f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 21:14:06 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.27 secs

#============================================================
# Rattle timestamp: 2017-04-18 21:14:11 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 21:14:32 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 21:14:49 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset, type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 21:17:08 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.29 secs

#============================================================
# Rattle timestamp: 2017-04-18 21:17:10 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 21:17:25 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset, type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 21:19:00 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 21:19:03 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.40 secs

#============================================================
# Rattle timestamp: 2017-04-18 21:19:05 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 21:19:50 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 21:20:21 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 43.76 secs

#============================================================
# Rattle timestamp: 2017-04-18 21:21:15 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 21:21:53 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 21:21:58 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 21:22:02 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 21:34:37 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 21:34:53 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.40 secs

#============================================================
# Rattle timestamp: 2017-04-18 21:34:58 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 21:35:47 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-18 21:42:36 x86_64-w64-mingw32 

# Remap variables. 

# Transform into a factor.

  crs$dataset[["TFC_samerace"]] <- as.factor(crs$dataset[["samerace"]])
  crs$dataset[["TFC_f_field_num"]] <- as.factor(crs$dataset[["f_field_num"]])
  crs$dataset[["TFC_f_race"]] <- as.factor(crs$dataset[["f_race"]])
  crs$dataset[["TFC_f_goal"]] <- as.factor(crs$dataset[["f_goal"]])
  crs$dataset[["TFC_f_dat_freq"]] <- as.factor(crs$dataset[["f_dat_freq"]])
  crs$dataset[["TFC_f_out_freq"]] <- as.factor(crs$dataset[["f_out_freq"]])
  crs$dataset[["TFC_m_race"]] <- as.factor(crs$dataset[["m_race"]])
  crs$dataset[["TFC_m_goal"]] <- as.factor(crs$dataset[["m_goal"]])
  crs$dataset[["TFC_m_out_freq"]] <- as.factor(crs$dataset[["m_out_freq"]])

  ol <- levels(crs$dataset[["TFC_samerace"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_samerace"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_field_num"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_field_num"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_race"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_goal"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_goal"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_dat_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_dat_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_out_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_out_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_race"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_goal"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_goal"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_out_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_out_freq"]]) <- nl

#============================================================
# Rattle timestamp: 2017-04-18 21:42:37 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 21:43:18 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_age", "m_imp_race", "m_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "TFC_samerace", "TFC_f_field_num",
     "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq",
     "TFC_m_race", "TFC_m_goal", "TFC_m_out_freq")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_age", "m_imp_race", "m_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 21:43:24 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.55 secs

#============================================================
# Rattle timestamp: 2017-04-18 21:43:27 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 21:43:37 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-18 21:47:21 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_age", "m_imp_race", "m_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "TFC_samerace", "TFC_f_field_num",
     "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq",
     "TFC_m_race", "TFC_m_goal", "TFC_m_out_freq")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_age", "m_imp_race", "m_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 21:47:25 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.49 secs

#============================================================
# Rattle timestamp: 2017-04-18 21:47:27 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 21:51:45 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("female_dec", "f_age", "f_imp_race", "f_imp_relig",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_age", "m_imp_race",
     "m_imp_relig", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2", "TFC_samerace",
     "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal", "TFC_m_out_freq")

crs$numeric <- c("female_dec", "f_age", "f_imp_race", "f_imp_relig",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_age", "m_imp_race",
     "m_imp_relig", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 21:51:55 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.28 secs

#============================================================
# Rattle timestamp: 2017-04-18 21:52:09 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 21:52:13 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 22:25:03 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("male_dec", "f_age", "f_imp_race", "f_imp_relig",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_age", "m_imp_race",
     "m_imp_relig", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2", "TFC_samerace",
     "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal", "TFC_m_out_freq")

crs$numeric <- c("male_dec", "f_age", "f_imp_race", "f_imp_relig",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_age", "m_imp_race",
     "m_imp_relig", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 22:25:12 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.29 secs

#============================================================
# Rattle timestamp: 2017-04-18 22:25:15 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 22:29:22 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:29:26 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:30:21 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=250)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 42.97 secs

#============================================================
# Rattle timestamp: 2017-04-18 22:31:10 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:31:30 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:31:57 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.010000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 1.24 mins

#============================================================
# Rattle timestamp: 2017-04-18 22:33:24 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:33:33 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:33:47 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(match) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=700,
      mtry=6,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 13.80 secs

#============================================================
# Rattle timestamp: 2017-04-18 22:34:30 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:34:52 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:35:20 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("female_dec", "f_age", "f_imp_race", "f_imp_relig",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_age", "m_imp_race",
     "m_imp_relig", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2", "TFC_samerace",
     "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal", "TFC_m_out_freq")

crs$numeric <- c("female_dec", "f_age", "f_imp_race", "f_imp_relig",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_age", "m_imp_race",
     "m_imp_relig", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 22:35:28 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(match) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=700,
      mtry=6,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 12.19 secs

#============================================================
# Rattle timestamp: 2017-04-18 22:35:48 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:35:52 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:35:57 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.010000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 1.14 mins

#============================================================
# Rattle timestamp: 2017-04-18 22:37:35 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:37:44 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:38:02 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

# The following variable selections have been noted.

crs$input <- c("female_dec", "f_age", "f_imp_race", "f_imp_relig",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_age", "m_imp_race",
     "m_imp_relig", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2", "TFC_samerace",
     "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal", "TFC_m_out_freq")

crs$numeric <- c("female_dec", "f_age", "f_imp_race", "f_imp_relig",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_age", "m_imp_race",
     "m_imp_relig", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 22:38:12 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.010000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 50.67 secs

#============================================================
# Rattle timestamp: 2017-04-18 22:39:17 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:39:23 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:39:52 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(match) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=700,
      mtry=6,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 8.22 secs

#============================================================
# Rattle timestamp: 2017-04-18 22:40:25 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:40:36 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:40:53 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.18 secs

#============================================================
# Rattle timestamp: 2017-04-18 22:40:55 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 22:42:24 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 22:53:13 x86_64-w64-mingw32 

# Perform missing value imputation. 

#============================================================
# Rattle timestamp: 2017-04-18 22:53:13 x86_64-w64-mingw32 

# Transform variables by imputing missing values. 

# Impute f_career_num.

crs$dataset[["IZR_f_career_num"]] <- crs$dataset[["f_career_num"]]

# Change all NAs to 0.

if (building)
{
  crs$dataset[["IZR_f_career_num"]][is.na(crs$dataset[["f_career_num"]])] <- 0
}

# When scoring, transform using the training data parameters:

if (scoring)
{
  crs$dataset[["IZR_f_career_num"]][is.na(crs$dataset[["f_career_num"]])] <- 0
}

# Impute m_field_num.

crs$dataset[["IZR_m_field_num"]] <- crs$dataset[["m_field_num"]]

# Change all NAs to 0.

if (building)
{
  crs$dataset[["IZR_m_field_num"]][is.na(crs$dataset[["m_field_num"]])] <- 0
}

# When scoring, transform using the training data parameters:

if (scoring)
{
  crs$dataset[["IZR_m_field_num"]][is.na(crs$dataset[["m_field_num"]])] <- 0
}

# Impute m_career_num.

crs$dataset[["IZR_m_career_num"]] <- crs$dataset[["m_career_num"]]

# Change all NAs to 0.

if (building)
{
  crs$dataset[["IZR_m_career_num"]][is.na(crs$dataset[["m_career_num"]])] <- 0
}

# When scoring, transform using the training data parameters:

if (scoring)
{
  crs$dataset[["IZR_m_career_num"]][is.na(crs$dataset[["m_career_num"]])] <- 0
}

#============================================================
# Rattle timestamp: 2017-04-18 22:53:14 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("female_dec", "f_age", "f_imp_race", "f_imp_relig",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_age", "m_imp_race",
     "m_imp_relig", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2", "TFC_samerace",
     "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal", "TFC_m_out_freq",
     "IZR_f_career_num", "IZR_m_field_num", "IZR_m_career_num")

crs$numeric <- c("female_dec", "f_age", "f_imp_race", "f_imp_relig",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_age", "m_imp_race",
     "m_imp_relig", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2", "IZR_f_career_num",
     "IZR_m_field_num", "IZR_m_career_num")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_race", "TFC_m_goal",
     "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 23:01:37 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_match_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 23:01:39 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 23:01:50 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_addon_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-18 23:01:52 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 23:36:27 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- NULL

crs$numeric <- NULL

crs$categoric <- NULL

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 23:37:52 x86_64-w64-mingw32 

# Remap variables. 

# Transform into a factor.

  crs$dataset[["TFC_samerace"]] <- as.factor(crs$dataset[["samerace"]])
  crs$dataset[["TFC_f_field_num"]] <- as.factor(crs$dataset[["f_field_num"]])
  crs$dataset[["TFC_f_race"]] <- as.factor(crs$dataset[["f_race"]])
  crs$dataset[["TFC_f_goal"]] <- as.factor(crs$dataset[["f_goal"]])
  crs$dataset[["TFC_f_dat_freq"]] <- as.factor(crs$dataset[["f_dat_freq"]])
  crs$dataset[["TFC_f_out_freq"]] <- as.factor(crs$dataset[["f_out_freq"]])
  crs$dataset[["TFC_m_field_num"]] <- as.factor(crs$dataset[["m_field_num"]])
  crs$dataset[["TFC_m_race"]] <- as.factor(crs$dataset[["m_race"]])
  crs$dataset[["TFC_m_goal"]] <- as.factor(crs$dataset[["m_goal"]])
  crs$dataset[["TFC_m_dat_freq"]] <- as.factor(crs$dataset[["m_dat_freq"]])
  crs$dataset[["TFC_m_out_freq"]] <- as.factor(crs$dataset[["m_out_freq"]])

  ol <- levels(crs$dataset[["TFC_samerace"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_samerace"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_field_num"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_field_num"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_race"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_goal"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_goal"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_dat_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_dat_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_out_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_out_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_field_num"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_field_num"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_race"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_goal"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_goal"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_dat_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_dat_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_out_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_out_freq"]]) <- nl

#============================================================
# Rattle timestamp: 2017-04-18 23:37:53 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- NULL

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 23:38:31 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.07 secs

#============================================================
# Rattle timestamp: 2017-04-18 23:38:42 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 23:39:35 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-18 23:40:27 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 23:40:30 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.35 secs

#============================================================
# Rattle timestamp: 2017-04-18 23:40:32 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-18 23:40:54 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 23:42:44 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 23:42:47 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.36 secs

#============================================================
# Rattle timestamp: 2017-04-18 23:42:49 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-18 23:43:17 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.45 secs

#============================================================
# Rattle timestamp: 2017-04-18 23:43:18 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-18 23:44:06 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 23:44:43 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(male_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 1.46 mins

#============================================================
# Rattle timestamp: 2017-04-18 23:46:16 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 23:48:15 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_age", "m_imp_race", "m_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "TFC_samerace", "TFC_f_field_num",
     "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq",
     "TFC_m_field_num", "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq",
     "TFC_m_out_freq")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_age", "m_imp_race", "m_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 23:48:20 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.49 secs

#============================================================
# Rattle timestamp: 2017-04-18 23:48:21 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-18 23:48:48 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 23:48:54 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(male_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 1.60 mins

#============================================================
# Rattle timestamp: 2017-04-18 23:50:37 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 23:50:57 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 23:51:20 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_age", "m_imp_race", "m_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "TFC_samerace", "TFC_f_field_num",
     "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq",
     "TFC_m_field_num", "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq",
     "TFC_m_out_freq")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_age", "m_imp_race", "m_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 23:51:23 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.49 secs

#============================================================
# Rattle timestamp: 2017-04-18 23:51:25 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-18 23:52:09 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 23:52:17 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 23:52:23 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 1.48 mins

#============================================================
# Rattle timestamp: 2017-04-18 23:53:57 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 23:54:10 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 23:55:05 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_age", "m_imp_race", "m_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "TFC_samerace", "TFC_f_field_num",
     "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq",
     "TFC_m_field_num", "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq",
     "TFC_m_out_freq")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "f_avg_like", "m_age", "m_imp_race", "m_imp_relig",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 23:55:12 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.44 secs

#============================================================
# Rattle timestamp: 2017-04-18 23:55:14 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 23:55:36 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 23:55:44 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 23:55:50 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.49 secs

#============================================================
# Rattle timestamp: 2017-04-18 23:55:52 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 23:56:01 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 23:56:08 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 1.49 mins

#============================================================
# Rattle timestamp: 2017-04-18 23:57:52 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 23:58:19 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "male_dec", "f_age",
     "f_imp_race", "f_imp_relig", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2", "TFC_samerace", "TFC_f_field_num", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num",
     "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("order", "interest_corr", "male_dec", "f_age",
     "f_imp_race", "f_imp_relig", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-18 23:58:23 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.31 secs

#============================================================
# Rattle timestamp: 2017-04-18 23:58:29 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-18 23:58:51 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-18 23:59:04 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 1.26 mins

#============================================================
# Rattle timestamp: 2017-04-19 00:00:39 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:00:51 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:01:21 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "female_dec", "f_age",
     "f_imp_race", "f_imp_relig", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2", "TFC_samerace", "TFC_f_field_num", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num",
     "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("order", "interest_corr", "female_dec", "f_age",
     "f_imp_race", "f_imp_relig", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 00:01:28 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.25 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:01:30 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-19 00:01:44 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:01:47 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:01:58 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 1.18 mins

#============================================================
# Rattle timestamp: 2017-04-19 00:03:22 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:03:35 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:04:23 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "female_dec", "f_age",
     "f_imp_race", "f_imp_relig", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2", "TFC_samerace", "TFC_f_field_num", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num",
     "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("order", "interest_corr", "female_dec", "f_age",
     "f_imp_race", "f_imp_relig", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 00:04:29 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.18 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:04:30 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-19 00:04:38 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:04:40 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:04:49 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 51.66 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:05:50 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:05:58 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:06:30 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset, type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset)

# Generate the confusion matrix showing counts.

table(crs$dataset$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:07:50 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 00:08:01 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.002500,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.39 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:08:03 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 00:08:11 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:08:15 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:08:24 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.38 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:08:27 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:08:51 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.007500,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.39 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:08:53 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 00:09:01 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:09:08 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:09:19 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=15,
           cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.39 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:09:21 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 00:09:28 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:09:38 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.37 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:09:41 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.38 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:09:42 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 00:09:48 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:09:52 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:09:58 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 00:13:17 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 00:13:20 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.38 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:13:23 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-19 00:13:25 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-19 00:15:25 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:15:42 x86_64-w64-mingw32 

# Regression model 

# Build a Regression model.

crs$glm <- glm(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    family=binomial(link="logit"))

# Generate a textual view of the Linear model.

print(summary(crs$glm))
cat(sprintf("Log likelihood: %.3f (%d df)\n",
            logLik(crs$glm)[1],
            attr(logLik(crs$glm), "df")))
cat(sprintf("Null/Residual deviance difference: %.3f (%d df)\n",
            crs$glm$null.deviance-crs$glm$deviance,
            crs$glm$df.null-crs$glm$df.residual))
cat(sprintf("Chi-square p-value: %.8f\n",
            dchisq(crs$glm$null.deviance-crs$glm$deviance,
                   crs$glm$df.null-crs$glm$df.residual)))
cat(sprintf("Pseudo R-Square (optimistic): %.8f\n",
             cor(crs$glm$y, crs$glm$fitted.values)))
cat('\n==== ANOVA ====\n\n')
print(anova(crs$glm, test="Chisq"))
cat("\n")

# Time taken: 3.13 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:15:50 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Linear model.

# Obtain the response from the Linear model.

crs$pr <- as.vector(ifelse(predict(crs$glm, type="response", newdata=crs$dataset[crs$validate, c(crs$input, crs$target)]) > 0.5, "1", "0"))

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:16:04 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Linear model.

# Obtain the response from the Linear model.

crs$pr <- as.vector(ifelse(predict(crs$glm, type="response", newdata=crs$dataset[crs$test, c(crs$input, crs$target)]) > 0.5, "1", "0"))

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:16:15 x86_64-w64-mingw32 

# Neural Network 

# Build a neural network model using the nnet package.

library(nnet, quietly=TRUE)

# Build the NNet model.

set.seed(199)
crs$nnet <- nnet(as.factor(male_dec) ~ .,
    data=crs$dataset[crs$sample,c(crs$input, crs$target)],
    size=20, skip=TRUE, MaxNWts=10000, trace=FALSE, maxit=100)

# Print the results of the modelling.

cat(sprintf("A %s network with %d weights.\n",
    paste(crs$nnet$n, collapse="-"),
    length(crs$nnet$wts)))
cat(sprintf("Inputs: %s.\n",
    paste(crs$nnet$coefnames, collapse=", ")))
cat(sprintf("Output: %s.\n",
    names(attr(crs$nnet$terms, "dataClasses"))[1]))
cat(sprintf("Sum of Squares Residuals: %.4f.\n",
    sum(residuals(crs$nnet) ^ 2)))
cat("\n")
print(summary(crs$nnet))
cat('\n')

# Time taken: 11.74 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:16:35 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Neural Net model.

# Obtain the response from the Neural Net model.

crs$pr <- predict(crs$nnet, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:16:48 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 2.17 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:16:55 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:17:14 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:17:25 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=700,
      mtry=6,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 12.40 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:17:44 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:17:52 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:17:58 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:23:53 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_match_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-19 00:23:55 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 00:23:57 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_addon_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-19 00:23:59 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 00:24:48 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$numeric <- c("m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 00:24:52 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.05 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:25:02 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.35 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:25:04 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-19 00:25:26 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:25:30 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:25:45 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("samerace", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$numeric <- c("samerace", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 00:25:48 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.33 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:26:46 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$numeric <- c("f_age", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 00:26:49 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.39 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:26:51 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-19 00:27:20 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:27:25 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:27:40 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minbucket=4,
           cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.43 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:27:43 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-19 00:27:59 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=15,
           minbucket=4,
           cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.44 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:28:01 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-19 00:28:08 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:28:13 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:28:36 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("female_dec", "f_age", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$numeric <- c("female_dec", "f_age", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 00:28:49 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(minsplit=15,
           minbucket=4,
           cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.24 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:28:52 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-19 00:29:00 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:29:06 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:29:30 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.010000,
                                                 minsplit=15,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 50.74 secs

#============================================================
# Rattle timestamp: 2017-04-19 00:30:34 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:30:44 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:30:55 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 00:31:14 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset, type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset)

# Generate the confusion matrix showing counts.

table(crs$dataset$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:02:30 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:02:50 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

# The following variable selections have been noted.

crs$input <- c("female_dec", "f_age", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$numeric <- c("female_dec", "f_age", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 11:03:04 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=15,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 37.57 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:03:46 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:03:51 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:04:08 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(match) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 0.77 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:04:12 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:04:22 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:05:20 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

#============================================================
# Rattle timestamp: 2017-04-19 11:05:27 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

# The following variable selections have been noted.

crs$input <- c("male_dec", "f_age", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$numeric <- c("male_dec", "f_age", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 11:05:31 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(match) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 0.78 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:05:35 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:05:56 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=15,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 41.04 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:07:05 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:07:22 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:07:39 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 40.98 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:08:25 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:08:37 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:09:12 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.015000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 36.94 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:09:53 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:10:00 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:10:33 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 34.36 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:11:12 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:11:19 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset)

# Generate the confusion matrix showing counts.

table(crs$dataset$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset)$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset)$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:14:40 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

# The following variable selections have been noted.

crs$input <- c("female_dec", "f_age", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$numeric <- c("female_dec", "f_age", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 11:15:00 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 32.90 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:15:42 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:15:50 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:17:03 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=700)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 56.54 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:18:18 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:18:42 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.050000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=700)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 46.68 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:19:35 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:19:46 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:20:12 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=15,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 32.62 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:20:51 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:20:58 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:22:41 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(match) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 0.67 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:22:45 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:23:02 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$numeric <- c("f_age", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_avg_attr", "m_avg_sinc", "m_avg_fun", "m_avg_intel",
     "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- NULL

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 11:23:08 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(match) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 0.95 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:23:24 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 38.57 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:24:08 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:25:16 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_match_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-19 11:25:17 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 11:25:54 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_addon_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-19 11:25:57 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 11:28:29 x86_64-w64-mingw32 

# Remap variables. 

# Transform into a factor.

  crs$dataset[["TFC_samerace"]] <- as.factor(crs$dataset[["samerace"]])
  crs$dataset[["TFC_f_field_num"]] <- as.factor(crs$dataset[["f_field_num"]])
  crs$dataset[["TFC_f_race"]] <- as.factor(crs$dataset[["f_race"]])
  crs$dataset[["TFC_f_goal"]] <- as.factor(crs$dataset[["f_goal"]])
  crs$dataset[["TFC_f_dat_freq"]] <- as.factor(crs$dataset[["f_dat_freq"]])
  crs$dataset[["TFC_f_out_freq"]] <- as.factor(crs$dataset[["f_out_freq"]])
  crs$dataset[["TFC_m_field_num"]] <- as.factor(crs$dataset[["m_field_num"]])
  crs$dataset[["TFC_m_race"]] <- as.factor(crs$dataset[["m_race"]])
  crs$dataset[["TFC_m_goal"]] <- as.factor(crs$dataset[["m_goal"]])
  crs$dataset[["TFC_m_dat_freq"]] <- as.factor(crs$dataset[["m_dat_freq"]])
  crs$dataset[["TFC_m_out_freq"]] <- as.factor(crs$dataset[["m_out_freq"]])

  ol <- levels(crs$dataset[["TFC_samerace"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_samerace"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_field_num"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_field_num"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_race"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_goal"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_goal"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_dat_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_dat_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_out_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_out_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_field_num"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_field_num"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_race"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_goal"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_goal"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_dat_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_dat_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_out_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_out_freq"]]) <- nl

#============================================================
# Rattle timestamp: 2017-04-19 11:28:30 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 11:28:46 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("order", "interest_corr", "f_age", "f_imp_race",
     "f_imp_relig", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_age",
     "m_imp_race", "m_imp_relig", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 11:28:55 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.34 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:28:59 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ match")

#============================================================
# Rattle timestamp: 2017-04-19 11:29:45 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 50.53 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:30:43 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:30:55 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:31:16 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "male_dec", "f_age",
     "f_imp_race", "f_imp_relig", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2", "TFC_samerace", "TFC_f_field_num", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num",
     "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("order", "interest_corr", "male_dec", "f_age",
     "f_imp_race", "f_imp_relig", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 11:31:23 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 45.34 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:32:29 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:32:38 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:33:11 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=700)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 1.29 mins

#============================================================
# Rattle timestamp: 2017-04-19 11:34:37 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:34:52 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:35:20 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

# The following variable selections have been noted.

crs$input <- c("male_dec", "f_age", "f_imp_race", "f_imp_relig",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_age", "m_imp_race",
     "m_imp_relig", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2", "TFC_samerace",
     "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race", "TFC_m_goal",
     "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("male_dec", "f_age", "f_imp_race", "f_imp_relig",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_age", "m_imp_race",
     "m_imp_relig", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1",
     "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 11:35:25 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(match ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.19 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:35:34 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(match) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 1.38 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:35:40 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:35:56 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 43.43 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:36:52 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:37:00 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:37:37 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=1000)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 1.78 mins

#============================================================
# Rattle timestamp: 2017-04-19 11:39:32 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:40:37 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.050000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=1000)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 1.52 mins

#============================================================
# Rattle timestamp: 2017-04-19 11:42:15 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:43:06 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1438 observations

# The following variable selections have been noted.

crs$input <- c("male_dec", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2", "TFC_samerace", "TFC_f_field_num", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num",
     "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("male_dec", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 11:43:24 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 39.32 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:44:09 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:44:16 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:44:47 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=700)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 1.12 mins

#============================================================
# Rattle timestamp: 2017-04-19 11:46:02 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:46:18 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(match) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 1.10 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:46:22 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:46:34 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:47:03 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.1*crs$nobs) # 410 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1643 observations

# The following variable selections have been noted.

crs$input <- c("male_dec", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2", "TFC_samerace", "TFC_f_field_num", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num",
     "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("male_dec", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 11:47:16 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(match) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 1.19 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:47:20 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:47:38 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:47:58 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 39.46 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:48:44 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:48:53 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:49:43 x86_64-w64-mingw32 

# Transform variables by rescaling. 

# The 'reshape' package provides the 'rescaler' function.

library(reshape, quietly=TRUE)

# Rescale f_age.

crs$dataset[["R01_f_age"]] <- crs$dataset[["f_age"]]

# Rescale to [0,1].

if (building)
{
  crs$dataset[["R01_f_age"]] <-  rescaler(crs$dataset[["f_age"]], "range")
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["R01_f_age"]] <- (crs$dataset[["f_age"]] - 19.000000)/abs(55.000000 - 19.000000)
}

# Rescale m_age.

crs$dataset[["R01_m_age"]] <- crs$dataset[["m_age"]]

# Rescale to [0,1].

if (building)
{
  crs$dataset[["R01_m_age"]] <-  rescaler(crs$dataset[["m_age"]], "range")
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["R01_m_age"]] <- (crs$dataset[["m_age"]] - 18.000000)/abs(42.000000 - 18.000000)
}

#============================================================
# Rattle timestamp: 2017-04-19 11:49:44 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("male_dec", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2", "TFC_samerace", "TFC_f_field_num", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num",
     "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq",
     "R01_f_age", "R01_m_age")

crs$numeric <- c("male_dec", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2", "R01_f_age", "R01_m_age")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 11:49:54 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.1*crs$nobs) # 410 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1643 observations

# The following variable selections have been noted.

crs$input <- c("male_dec", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2", "TFC_samerace", "TFC_f_field_num", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num",
     "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq",
     "R01_f_age", "R01_m_age")

crs$numeric <- c("male_dec", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2", "R01_f_age", "R01_m_age")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 11:50:00 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 40.74 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:50:51 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:50:57 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:51:08 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset)

# Generate the confusion matrix showing counts.

table(crs$dataset$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:51:29 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:51:35 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset)

# Generate the confusion matrix showing counts.

table(crs$dataset$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:51:45 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:52:30 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.1*crs$nobs) # 410 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1643 observations

# The following variable selections have been noted.

crs$input <- c("female_dec", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2", "TFC_samerace", "TFC_f_field_num", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num",
     "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq",
     "R01_f_age", "R01_m_age")

crs$numeric <- c("female_dec", "f_avg_attr", "f_avg_sinc", "f_avg_fun",
     "f_avg_intel", "f_avg_amb", "f_avg_like", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "m_avg_like", "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1",
     "m_interests_pca_vec_2", "R01_f_age", "R01_m_age")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "match"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 11:52:39 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 38.58 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:53:35 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:53:45 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:55:08 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(match) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 1.18 secs

#============================================================
# Rattle timestamp: 2017-04-19 11:55:11 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:55:21 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 11:55:42 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(match ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=700)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 1.31 mins

#============================================================
# Rattle timestamp: 2017-04-19 12:00:50 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$match, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 12:01:18 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.1*crs$nobs) # 410 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1643 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq", "R01_f_age",
     "R01_m_age")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "R01_f_age", "R01_m_age")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 12:01:29 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 48.08 secs

#============================================================
# Rattle timestamp: 2017-04-19 12:02:23 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 12:02:35 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Plot the relative importance of the variables.

ada::varplot(crs$ada)

#============================================================
# Rattle timestamp: 2017-04-19 12:04:35 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.29 secs

#============================================================
# Rattle timestamp: 2017-04-19 12:04:37 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 12:04:53 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.005000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 59.12 secs

#============================================================
# Rattle timestamp: 2017-04-19 12:05:57 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 12:06:07 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 12:06:39 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.050000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=700)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 52.77 secs

#============================================================
# Rattle timestamp: 2017-04-19 12:07:38 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 12:08:09 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=15,
                                                 xval=10),
                    iter=700)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 1.29 mins

#============================================================
# Rattle timestamp: 2017-04-19 12:09:32 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 12:10:09 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=5,
                                                 xval=10),
                    iter=700)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 1.31 mins

#============================================================
# Rattle timestamp: 2017-04-19 12:11:35 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 13:07:52 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.5*crs$nobs) # 2052 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.1*crs$nobs) # 410 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 1643 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq", "R01_f_age",
     "R01_m_age")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_interests_pca_vec_1", "f_interests_pca_vec_2",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "R01_f_age", "R01_m_age")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 13:08:04 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(male_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=10,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 47.47 secs

#============================================================
# Rattle timestamp: 2017-04-19 13:09:10 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 13:09:22 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 13:12:33 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 2.56 secs

#============================================================
# Rattle timestamp: 2017-04-19 13:12:39 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 13:12:54 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 13:30:01 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_match_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-19 13:30:03 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 13:30:05 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 13:30:07 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "PCAVector1",
     "PCAVector2")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 13:30:13 x86_64-w64-mingw32 

# Load the data.

crs$dataset <- read.csv("file:///C:/Users/VJ/Documents/MSBA/Machine Learning II/Final Project/data exploration/pca_addon_dataset.csv", na.strings=c(".", "NA", "", "?"), strip.white=TRUE, encoding="UTF-8")

#============================================================
# Rattle timestamp: 2017-04-19 13:30:16 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field", "f_field_num", "f_race",
     "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq",
     "f_out_freq", "f_career", "f_career_num", "f_like_sports",
     "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums",
     "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing",
     "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies",
     "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga",
     "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel",
     "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr",
     "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb",
     "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel",
     "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr",
     "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb",
     "f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "male_id", "m_rate_f_attr",
     "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb",
     "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before",
     "m_est_matches", "m_age", "m_field", "m_field_num",
     "m_race", "m_imp_race", "m_imp_relig", "m_goal",
     "m_dat_freq", "m_out_freq", "m_career", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4",
     "f_interests_pca_vec_5", "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8",
     "f_interests_pca_vec_9", "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_oppgender_perception_pca_vec_3", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3",
     "m_self_perception_pca_vec_4", "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3",
     "m_interests_pca_vec_4", "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7",
     "m_interests_pca_vec_8", "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$numeric <- c("order", "interest_corr", "match", "calls_from_female",
     "calls_from_male", "calls_to_female", "calls_to_male", "female_dec",
     "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc",
     "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar",
     "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches",
     "f_age", "f_field_num", "f_race", "f_imp_race",
     "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq",
     "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise",
     "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking",
     "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv",
     "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music",
     "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr",
     "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb",
     "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel",
     "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr",
     "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb",
     "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun",
     "f_rate_self_intel", "f_rate_self_amb", "f_avg_attr", "f_avg_sinc",
     "f_avg_fun", "f_avg_intel", "f_avg_amb", "f_avg_like",
     "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel",
     "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like",
     "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age",
     "m_field_num", "m_race", "m_imp_race", "m_imp_relig",
     "m_goal", "m_dat_freq", "m_out_freq", "m_career_num",
     "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining",
     "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming",
     "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater",
     "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping",
     "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc",
     "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar",
     "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun",
     "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc",
     "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar",
     "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel",
     "m_rate_self_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "m_avg_like", "f_pref_pca_vec_1",
     "f_pref_pca_vec_2", "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2",
     "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4",
     "f_interests_pca_vec_1", "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4",
     "f_interests_pca_vec_5", "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8",
     "f_interests_pca_vec_9", "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1",
     "m_pref_pca_vec_2", "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2",
     "m_oppgender_perception_pca_vec_3", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3",
     "m_self_perception_pca_vec_4", "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3",
     "m_interests_pca_vec_4", "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7",
     "m_interests_pca_vec_8", "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$categoric <- c("f_field", "f_career", "m_field", "m_career")

crs$target  <- "samerace"
crs$risk    <- NULL
crs$ident   <- c("X", "pair_id")
crs$ignore  <- NULL
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 13:38:05 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3",
     "f_self_perception_pca_vec_4", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "f_interests_pca_vec_3",
     "f_interests_pca_vec_4", "f_interests_pca_vec_5", "f_interests_pca_vec_6", "f_interests_pca_vec_7",
     "f_interests_pca_vec_8", "f_interests_pca_vec_9", "f_interests_pca_vec_10", "f_interests_pca_vec_11",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "m_interests_pca_vec_3", "m_interests_pca_vec_4", "m_interests_pca_vec_5", "m_interests_pca_vec_6",
     "m_interests_pca_vec_7", "m_interests_pca_vec_8", "m_interests_pca_vec_9", "m_interests_pca_vec_10",
     "m_interests_pca_vec_11")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3",
     "f_self_perception_pca_vec_4", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "f_interests_pca_vec_3",
     "f_interests_pca_vec_4", "f_interests_pca_vec_5", "f_interests_pca_vec_6", "f_interests_pca_vec_7",
     "f_interests_pca_vec_8", "f_interests_pca_vec_9", "f_interests_pca_vec_10", "f_interests_pca_vec_11",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "m_interests_pca_vec_3", "m_interests_pca_vec_4", "m_interests_pca_vec_5", "m_interests_pca_vec_6",
     "m_interests_pca_vec_7", "m_interests_pca_vec_8", "m_interests_pca_vec_9", "m_interests_pca_vec_10",
     "m_interests_pca_vec_11")

crs$categoric <- NULL

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 13:38:40 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.61 secs

#============================================================
# Rattle timestamp: 2017-04-19 13:38:46 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-19 13:38:52 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 13:40:58 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 13:46:55 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3",
     "f_self_perception_pca_vec_4", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "f_interests_pca_vec_3",
     "f_interests_pca_vec_4", "f_interests_pca_vec_5", "f_interests_pca_vec_6", "f_interests_pca_vec_7",
     "f_interests_pca_vec_8", "f_interests_pca_vec_9", "f_interests_pca_vec_10", "f_interests_pca_vec_11",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "m_interests_pca_vec_3", "m_interests_pca_vec_4", "m_interests_pca_vec_5", "m_interests_pca_vec_6",
     "m_interests_pca_vec_7", "m_interests_pca_vec_8", "m_interests_pca_vec_9", "m_interests_pca_vec_10",
     "m_interests_pca_vec_11")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3",
     "f_self_perception_pca_vec_4", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "f_interests_pca_vec_3",
     "f_interests_pca_vec_4", "f_interests_pca_vec_5", "f_interests_pca_vec_6", "f_interests_pca_vec_7",
     "f_interests_pca_vec_8", "f_interests_pca_vec_9", "f_interests_pca_vec_10", "f_interests_pca_vec_11",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "m_interests_pca_vec_3", "m_interests_pca_vec_4", "m_interests_pca_vec_5", "m_interests_pca_vec_6",
     "m_interests_pca_vec_7", "m_interests_pca_vec_8", "m_interests_pca_vec_9", "m_interests_pca_vec_10",
     "m_interests_pca_vec_11")

crs$categoric <- NULL

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 13:47:00 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.62 secs

#============================================================
# Rattle timestamp: 2017-04-19 13:47:03 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 13:49:33 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3",
     "f_self_perception_pca_vec_4", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "f_interests_pca_vec_3",
     "f_interests_pca_vec_4", "f_interests_pca_vec_5", "f_interests_pca_vec_6", "f_interests_pca_vec_7",
     "f_interests_pca_vec_8", "f_interests_pca_vec_9", "f_interests_pca_vec_10", "f_interests_pca_vec_11",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "m_interests_pca_vec_3", "m_interests_pca_vec_4", "m_interests_pca_vec_5", "m_interests_pca_vec_6",
     "m_interests_pca_vec_7", "m_interests_pca_vec_8", "m_interests_pca_vec_9", "m_interests_pca_vec_10",
     "m_interests_pca_vec_11")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3",
     "f_self_perception_pca_vec_4", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "f_interests_pca_vec_3",
     "f_interests_pca_vec_4", "f_interests_pca_vec_5", "f_interests_pca_vec_6", "f_interests_pca_vec_7",
     "f_interests_pca_vec_8", "f_interests_pca_vec_9", "f_interests_pca_vec_10", "f_interests_pca_vec_11",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "m_interests_pca_vec_3", "m_interests_pca_vec_4", "m_interests_pca_vec_5", "m_interests_pca_vec_6",
     "m_interests_pca_vec_7", "m_interests_pca_vec_8", "m_interests_pca_vec_9", "m_interests_pca_vec_10",
     "m_interests_pca_vec_11")

crs$categoric <- NULL

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 13:49:59 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3",
     "f_self_perception_pca_vec_4", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "f_interests_pca_vec_3",
     "f_interests_pca_vec_4", "f_interests_pca_vec_5", "f_interests_pca_vec_6", "f_interests_pca_vec_7",
     "f_interests_pca_vec_8", "f_interests_pca_vec_9", "f_interests_pca_vec_10", "f_interests_pca_vec_11",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "m_interests_pca_vec_3", "m_interests_pca_vec_4", "m_interests_pca_vec_5", "m_interests_pca_vec_6",
     "m_interests_pca_vec_7", "m_interests_pca_vec_8", "m_interests_pca_vec_9", "m_interests_pca_vec_10",
     "m_interests_pca_vec_11")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "f_avg_like", "m_avg_attr", "m_avg_sinc",
     "m_avg_fun", "m_avg_intel", "m_avg_amb", "m_avg_like",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3",
     "f_self_perception_pca_vec_4", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "f_interests_pca_vec_3",
     "f_interests_pca_vec_4", "f_interests_pca_vec_5", "f_interests_pca_vec_6", "f_interests_pca_vec_7",
     "f_interests_pca_vec_8", "f_interests_pca_vec_9", "f_interests_pca_vec_10", "f_interests_pca_vec_11",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "m_interests_pca_vec_3", "m_interests_pca_vec_4", "m_interests_pca_vec_5", "m_interests_pca_vec_6",
     "m_interests_pca_vec_7", "m_interests_pca_vec_8", "m_interests_pca_vec_9", "m_interests_pca_vec_10",
     "m_interests_pca_vec_11")

crs$categoric <- NULL

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 13:50:03 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.60 secs

#============================================================
# Rattle timestamp: 2017-04-19 13:50:05 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-19 13:50:40 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.70 secs

#============================================================
# Rattle timestamp: 2017-04-19 13:50:43 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-19 13:51:47 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.050000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.29 secs

#============================================================
# Rattle timestamp: 2017-04-19 13:51:50 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-19 13:52:51 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$categoric <- NULL

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 13:52:57 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.050000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.28 secs

#============================================================
# Rattle timestamp: 2017-04-19 13:53:00 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-19 13:53:17 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.70 secs

#============================================================
# Rattle timestamp: 2017-04-19 13:53:19 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-19 13:54:01 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.58 secs

#============================================================
# Rattle timestamp: 2017-04-19 13:54:04 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-19 13:56:00 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.008000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.63 secs

#============================================================
# Rattle timestamp: 2017-04-19 13:56:02 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-19 13:58:40 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$categoric <- NULL

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 13:58:44 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.008000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.64 secs

#============================================================
# Rattle timestamp: 2017-04-19 13:58:46 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:04:18 x86_64-w64-mingw32 

# Transform variables by rescaling. 

# Rescale samerace.

crs$dataset[["RRC_samerace"]] <- crs$dataset[["samerace"]]

# Recenter and rescale the data around 0.

if (building)
{
  crs$dataset[["RRC_samerace"]] <-
    scale(crs$dataset[["samerace"]])[,1]
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["RRC_samerace"]] <- (crs$dataset[["samerace"]] - 0.401462)/0.490254
}

# Rescale f_field_num.

crs$dataset[["RRC_f_field_num"]] <- crs$dataset[["f_field_num"]]

# Recenter and rescale the data around 0.

if (building)
{
  crs$dataset[["RRC_f_field_num"]] <-
    scale(crs$dataset[["f_field_num"]])[,1]
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["RRC_f_field_num"]] <- (crs$dataset[["f_field_num"]] - 7.991474)/3.918477
}

# Rescale f_race.

crs$dataset[["RRC_f_race"]] <- crs$dataset[["f_race"]]

# Recenter and rescale the data around 0.

if (building)
{
  crs$dataset[["RRC_f_race"]] <-
    scale(crs$dataset[["f_race"]])[,1]
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["RRC_f_race"]] <- (crs$dataset[["f_race"]] - 2.784409)/1.228142
}

# Rescale f_goal.

crs$dataset[["RRC_f_goal"]] <- crs$dataset[["f_goal"]]

# Recenter and rescale the data around 0.

if (building)
{
  crs$dataset[["RRC_f_goal"]] <-
    scale(crs$dataset[["f_goal"]])[,1]
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["RRC_f_goal"]] <- (crs$dataset[["f_goal"]] - 2.085262)/1.382161
}

# Rescale f_dat_freq.

crs$dataset[["RRC_f_dat_freq"]] <- crs$dataset[["f_dat_freq"]]

# Recenter and rescale the data around 0.

if (building)
{
  crs$dataset[["RRC_f_dat_freq"]] <-
    scale(crs$dataset[["f_dat_freq"]])[,1]
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["RRC_f_dat_freq"]] <- (crs$dataset[["f_dat_freq"]] - 5.153959)/1.446302
}

# Rescale f_out_freq.

crs$dataset[["RRC_f_out_freq"]] <- crs$dataset[["f_out_freq"]]

# Recenter and rescale the data around 0.

if (building)
{
  crs$dataset[["RRC_f_out_freq"]] <-
    scale(crs$dataset[["f_out_freq"]])[,1]
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["RRC_f_out_freq"]] <- (crs$dataset[["f_out_freq"]] - 2.137637)/1.056083
}

# Rescale m_field_num.

crs$dataset[["RRC_m_field_num"]] <- crs$dataset[["m_field_num"]]

# Recenter and rescale the data around 0.

if (building)
{
  crs$dataset[["RRC_m_field_num"]] <-
    scale(crs$dataset[["m_field_num"]])[,1]
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["RRC_m_field_num"]] <- (crs$dataset[["m_field_num"]] - 7.351523)/3.592476
}

# Rescale m_race.

crs$dataset[["RRC_m_race"]] <- crs$dataset[["m_race"]]

# Recenter and rescale the data around 0.

if (building)
{
  crs$dataset[["RRC_m_race"]] <-
    scale(crs$dataset[["m_race"]])[,1]
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["RRC_m_race"]] <- (crs$dataset[["m_race"]] - 2.733496)/1.234104
}

# Rescale m_goal.

crs$dataset[["RRC_m_goal"]] <- crs$dataset[["m_goal"]]

# Recenter and rescale the data around 0.

if (building)
{
  crs$dataset[["RRC_m_goal"]] <-
    scale(crs$dataset[["m_goal"]])[,1]
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["RRC_m_goal"]] <- (crs$dataset[["m_goal"]] - 2.142996)/1.414994
}

# Rescale m_dat_freq.

crs$dataset[["RRC_m_dat_freq"]] <- crs$dataset[["m_dat_freq"]]

# Recenter and rescale the data around 0.

if (building)
{
  crs$dataset[["RRC_m_dat_freq"]] <-
    scale(crs$dataset[["m_dat_freq"]])[,1]
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["RRC_m_dat_freq"]] <- (crs$dataset[["m_dat_freq"]] - 4.861389)/1.426405
}

# Rescale m_out_freq.

crs$dataset[["RRC_m_out_freq"]] <- crs$dataset[["m_out_freq"]]

# Recenter and rescale the data around 0.

if (building)
{
  crs$dataset[["RRC_m_out_freq"]] <-
    scale(crs$dataset[["m_out_freq"]])[,1]
}

# When scoring transform using the training data parameters.

if (scoring)
{
  crs$dataset[["RRC_m_out_freq"]] <- (crs$dataset[["m_out_freq"]] - 2.177588)/1.151694
}

#============================================================
# Rattle timestamp: 2017-04-19 14:04:20 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11", "RRC_samerace",
     "RRC_f_field_num", "RRC_f_race", "RRC_f_goal", "RRC_f_dat_freq",
     "RRC_f_out_freq", "RRC_m_field_num", "RRC_m_race", "RRC_m_goal",
     "RRC_m_dat_freq", "RRC_m_out_freq")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11", "RRC_samerace",
     "RRC_f_field_num", "RRC_f_race", "RRC_f_goal", "RRC_f_dat_freq",
     "RRC_f_out_freq", "RRC_m_field_num", "RRC_m_race", "RRC_m_goal",
     "RRC_m_dat_freq", "RRC_m_out_freq")

crs$categoric <- NULL

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_like")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 14:05:08 x86_64-w64-mingw32 

# Remap variables. 

# Transform into a factor.

  crs$dataset[["TFC_samerace"]] <- as.factor(crs$dataset[["samerace"]])
  crs$dataset[["TFC_f_field_num"]] <- as.factor(crs$dataset[["f_field_num"]])
  crs$dataset[["TFC_f_race"]] <- as.factor(crs$dataset[["f_race"]])
  crs$dataset[["TFC_f_goal"]] <- as.factor(crs$dataset[["f_goal"]])
  crs$dataset[["TFC_f_dat_freq"]] <- as.factor(crs$dataset[["f_dat_freq"]])
  crs$dataset[["TFC_f_out_freq"]] <- as.factor(crs$dataset[["f_out_freq"]])
  crs$dataset[["TFC_m_field_num"]] <- as.factor(crs$dataset[["m_field_num"]])
  crs$dataset[["TFC_m_race"]] <- as.factor(crs$dataset[["m_race"]])
  crs$dataset[["TFC_m_goal"]] <- as.factor(crs$dataset[["m_goal"]])
  crs$dataset[["TFC_m_dat_freq"]] <- as.factor(crs$dataset[["m_dat_freq"]])
  crs$dataset[["TFC_m_out_freq"]] <- as.factor(crs$dataset[["m_out_freq"]])

  ol <- levels(crs$dataset[["TFC_samerace"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_samerace"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_field_num"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_field_num"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_race"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_goal"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_goal"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_dat_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_dat_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_f_out_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_f_out_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_field_num"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_field_num"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_race"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_race"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_goal"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_goal"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_dat_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_dat_freq"]]) <- nl

  ol <- levels(crs$dataset[["TFC_m_out_freq"]])
  lol <- length(ol)
  nl <- c(sprintf("[%s,%s]", ol[1], ol[1]), sprintf("(%s,%s]", ol[-lol], ol[-1]))
  levels(crs$dataset[["TFC_m_out_freq"]]) <- nl

#============================================================
# Rattle timestamp: 2017-04-19 14:05:09 x86_64-w64-mingw32 

# Note the user selections. 

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11", "TFC_samerace",
     "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race", "TFC_m_goal",
     "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_like", "RRC_samerace", "RRC_f_field_num", "RRC_f_race", "RRC_f_goal", "RRC_f_dat_freq", "RRC_f_out_freq", "RRC_m_field_num", "RRC_m_race", "RRC_m_goal", "RRC_m_dat_freq", "RRC_m_out_freq")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 14:05:17 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11", "TFC_samerace",
     "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race", "TFC_m_goal",
     "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_like", "RRC_samerace", "RRC_f_field_num", "RRC_f_race", "RRC_f_goal", "RRC_f_dat_freq", "RRC_f_out_freq", "RRC_m_field_num", "RRC_m_race", "RRC_m_goal", "RRC_m_dat_freq", "RRC_m_out_freq")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 14:05:23 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.008000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.66 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:05:26 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:05:46 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.050000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.33 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:05:48 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:06:53 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.001000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.80 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:06:57 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:07:17 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.69 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:07:20 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:08:39 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11", "TFC_samerace",
     "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race", "TFC_m_goal",
     "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_like", "RRC_samerace", "RRC_f_field_num", "RRC_f_race", "RRC_f_goal", "RRC_f_dat_freq", "RRC_f_out_freq", "RRC_m_field_num", "RRC_m_race", "RRC_m_goal", "RRC_m_dat_freq", "RRC_m_out_freq")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 14:08:44 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.60 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:08:46 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:09:27 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.76 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:09:29 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:24:06 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11", "TFC_samerace",
     "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq",
     "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race", "TFC_m_goal",
     "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_like", "RRC_samerace", "RRC_f_field_num", "RRC_f_race", "RRC_f_goal", "RRC_f_dat_freq", "RRC_f_out_freq", "RRC_m_field_num", "RRC_m_race", "RRC_m_goal", "RRC_m_dat_freq", "RRC_m_out_freq")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 14:24:12 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.75 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:24:20 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:24:23 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.66 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:24:25 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:24:53 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$categoric <- NULL

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_like", "RRC_samerace", "RRC_f_field_num", "RRC_f_race", "RRC_f_goal", "RRC_f_dat_freq", "RRC_f_out_freq", "RRC_m_field_num", "RRC_m_race", "RRC_m_goal", "RRC_m_dat_freq", "RRC_m_out_freq", "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 14:24:57 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.67 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:25:00 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:25:39 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.025000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.46 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:25:41 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:28:53 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$categoric <- NULL

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_like", "RRC_samerace", "RRC_f_field_num", "RRC_f_race", "RRC_f_goal", "RRC_f_dat_freq", "RRC_f_out_freq", "RRC_m_field_num", "RRC_m_race", "RRC_m_goal", "RRC_m_dat_freq", "RRC_m_out_freq", "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 14:28:58 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.025000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.41 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:29:02 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:29:23 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.050000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.28 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:29:38 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.025000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.41 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:29:46 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
    control=rpart.control(usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.59 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:29:49 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:30:35 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 14:36:26 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$categoric <- NULL

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_like", "RRC_samerace", "RRC_f_field_num", "RRC_f_race", "RRC_f_goal", "RRC_f_dat_freq", "RRC_f_out_freq", "RRC_m_field_num", "RRC_m_race", "RRC_m_goal", "RRC_m_dat_freq", "RRC_m_out_freq", "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 14:36:38 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.025000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.42 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:36:41 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:36:53 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 14:38:20 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.005000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.74 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:38:22 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:38:43 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(female_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.008000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.70 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:38:45 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ female_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:39:27 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 14:40:38 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$numeric <- c("f_avg_attr", "f_avg_sinc", "f_avg_fun", "f_avg_intel",
     "f_avg_amb", "m_avg_attr", "m_avg_sinc", "m_avg_fun",
     "m_avg_intel", "m_avg_amb", "f_pref_pca_vec_1", "f_pref_pca_vec_2",
     "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1", "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1",
     "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3", "f_self_perception_pca_vec_4", "f_interests_pca_vec_1",
     "f_interests_pca_vec_2", "f_interests_pca_vec_3", "f_interests_pca_vec_4", "f_interests_pca_vec_5",
     "f_interests_pca_vec_6", "f_interests_pca_vec_7", "f_interests_pca_vec_8", "f_interests_pca_vec_9",
     "f_interests_pca_vec_10", "f_interests_pca_vec_11", "m_pref_pca_vec_1", "m_pref_pca_vec_2",
     "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1", "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3",
     "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2", "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4",
     "m_interests_pca_vec_1", "m_interests_pca_vec_2", "m_interests_pca_vec_3", "m_interests_pca_vec_4",
     "m_interests_pca_vec_5", "m_interests_pca_vec_6", "m_interests_pca_vec_7", "m_interests_pca_vec_8",
     "m_interests_pca_vec_9", "m_interests_pca_vec_10", "m_interests_pca_vec_11")

crs$categoric <- NULL

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_age", "f_field", "f_field_num", "f_race", "f_imp_race", "f_imp_relig", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_age", "m_field", "m_field_num", "m_race", "m_imp_race", "m_imp_relig", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_like", "RRC_samerace", "RRC_f_field_num", "RRC_f_race", "RRC_f_goal", "RRC_f_dat_freq", "RRC_f_out_freq", "RRC_m_field_num", "RRC_m_race", "RRC_m_goal", "RRC_m_dat_freq", "RRC_m_out_freq", "TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 14:40:44 x86_64-w64-mingw32 

# Decision Tree 

# The 'rpart' package provides the 'rpart' function.

library(rpart, quietly=TRUE)

# Reset the random number seed to obtain the same results each time.

set.seed(crv$seed)

# Build the Decision Tree model.

crs$rpart <- rpart(male_dec ~ .,
    data=crs$dataset[crs$train, c(crs$input, crs$target)],
    method="class",
    parms=list(split="information"),
      control=rpart.control(cp=0.008000,
        usesurrogate=0, 
        maxsurrogate=0))

# Generate a textual view of the Decision Tree model.

print(crs$rpart)
printcp(crs$rpart)
cat("\n")

# Time taken: 0.63 secs

#============================================================
# Rattle timestamp: 2017-04-19 14:40:46 x86_64-w64-mingw32 

# Plot the resulting Decision Tree. 

# We use the rpart.plot package.

fancyRpartPlot(crs$rpart, main="Decision Tree pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-19 14:41:51 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Decision Tree model.

# Obtain the response from the Decision Tree model.

crs$pr <- predict(crs$rpart, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="class")

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 15:16:02 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3",
     "f_self_perception_pca_vec_4", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "f_interests_pca_vec_3",
     "f_interests_pca_vec_4", "f_interests_pca_vec_5", "f_interests_pca_vec_6", "f_interests_pca_vec_7",
     "f_interests_pca_vec_8", "f_interests_pca_vec_9", "f_interests_pca_vec_10", "f_interests_pca_vec_11",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "m_interests_pca_vec_3", "m_interests_pca_vec_4", "m_interests_pca_vec_5", "m_interests_pca_vec_6",
     "m_interests_pca_vec_7", "m_interests_pca_vec_8", "m_interests_pca_vec_9", "m_interests_pca_vec_10",
     "m_interests_pca_vec_11", "TFC_samerace", "TFC_f_field_num", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num",
     "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3",
     "f_self_perception_pca_vec_4", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "f_interests_pca_vec_3",
     "f_interests_pca_vec_4", "f_interests_pca_vec_5", "f_interests_pca_vec_6", "f_interests_pca_vec_7",
     "f_interests_pca_vec_8", "f_interests_pca_vec_9", "f_interests_pca_vec_10", "f_interests_pca_vec_11",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "m_interests_pca_vec_3", "m_interests_pca_vec_4", "m_interests_pca_vec_5", "m_interests_pca_vec_6",
     "m_interests_pca_vec_7", "m_interests_pca_vec_8", "m_interests_pca_vec_9", "m_interests_pca_vec_10",
     "m_interests_pca_vec_11")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "male_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "female_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_like", "RRC_samerace", "RRC_f_field_num", "RRC_f_race", "RRC_f_goal", "RRC_f_dat_freq", "RRC_f_out_freq", "RRC_m_field_num", "RRC_m_race", "RRC_m_goal", "RRC_m_dat_freq", "RRC_m_out_freq")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 15:16:10 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 5.05 secs

#============================================================
# Rattle timestamp: 2017-04-19 15:16:20 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 15:16:52 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(male_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.010000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 2.04 mins

#============================================================
# Rattle timestamp: 2017-04-19 15:19:01 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Display tree number 1.

drawTreesAda(crs$ada, 1, ": pca_addon_dataset.csv $ male_dec")

# Display tree number 2.

drawTreesAda(crs$ada, 2, ": pca_addon_dataset.csv $ male_dec")

# Display tree number 3.

drawTreesAda(crs$ada, 3, ": pca_addon_dataset.csv $ male_dec")

# Display tree number 4.

drawTreesAda(crs$ada, 4, ": pca_addon_dataset.csv $ male_dec")

#============================================================
# Rattle timestamp: 2017-04-19 15:20:38 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=700,
      mtry=8,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 26.97 secs

#============================================================
# Rattle timestamp: 2017-04-19 15:21:10 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 15:21:28 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 15:23:34 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(male_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.025000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=800)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 3.13 mins

#============================================================
# Rattle timestamp: 2017-04-19 15:26:46 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 15:27:53 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(male_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.001000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 2.24 mins

#============================================================
# Rattle timestamp: 2017-04-19 15:31:11 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 15:32:15 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$sample, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$sample, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$sample, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$sample, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$sample, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$sample, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$sample, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$sample, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$sample, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 15:32:31 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 15:33:44 x86_64-w64-mingw32 

# Evaluate model performance. 

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the ada model on pca_addon_dataset.csv [validate].

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)], type="prob")[,2]

# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve Ada Boost pca_addon_dataset.csv [validate] male_dec")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the rf model on pca_addon_dataset.csv [validate].

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]), type="prob")[,2]

# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve Random Forest pca_addon_dataset.csv [validate] male_dec")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the ksvm model on pca_addon_dataset.csv [validate].

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]), type="probabilities")[,2]

# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve SVM pca_addon_dataset.csv [validate] male_dec")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

#============================================================
# Rattle timestamp: 2017-04-19 15:34:47 x86_64-w64-mingw32 

# Evaluate model performance. 

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the ada model on pca_addon_dataset.csv [test].

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="prob")[,2]

# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve Ada Boost pca_addon_dataset.csv [test] male_dec")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the rf model on pca_addon_dataset.csv [test].

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]), type="prob")[,2]

# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve Random Forest pca_addon_dataset.csv [test] male_dec")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

# ROC Curve: requires the ROCR package.

library(ROCR)

# ROC Curve: requires the ggplot2 package.

library(ggplot2, quietly=TRUE)

# Generate an ROC Curve for the ksvm model on pca_addon_dataset.csv [test].

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]), type="probabilities")[,2]

# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}

pe <- performance(pred, "tpr", "fpr")
au <- performance(pred, "auc")@y.values[[1]]
pd <- data.frame(fpr=unlist(pe@x.values), tpr=unlist(pe@y.values))
p <- ggplot(pd, aes(x=fpr, y=tpr))
p <- p + geom_line(colour="red")
p <- p + xlab("False Positive Rate") + ylab("True Positive Rate")
p <- p + ggtitle("ROC Curve SVM pca_addon_dataset.csv [test] male_dec")
p <- p + theme(plot.title=element_text(size=10))
p <- p + geom_line(data=data.frame(), aes(x=c(0,1), y=c(0,1)), colour="grey")
p <- p + annotate("text", x=0.50, y=0.00, hjust=0, vjust=0, size=5,
                   label=paste("AUC =", round(au, 2)))
print(p)

# Calculate the area under the curve for the plot.


# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
performance(pred, "auc")

#============================================================
# Rattle timestamp: 2017-04-19 15:35:11 x86_64-w64-mingw32 

# Evaluate model performance. 

# Precision/Recall Plot: requires the ROCR package

library(ROCR)

# Generate a Precision/Recall Plot for the ada model on pca_addon_dataset.csv [test].

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="prob")[,2]

# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
ROCR::plot(performance(pred, "prec", "rec"), col="#CC0000FF", lty=1, add=FALSE)


# Precision/Recall Plot: requires the ROCR package

library(ROCR)

# Generate a Precision/Recall Plot for the rf model on pca_addon_dataset.csv [test].

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]), type="prob")[,2]

# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
ROCR::plot(performance(pred, "prec", "rec"), col="#00CC00FF", lty=2, add=TRUE)


# Precision/Recall Plot: requires the ROCR package

library(ROCR)

# Generate a Precision/Recall Plot for the ksvm model on pca_addon_dataset.csv [test].

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]), type="probabilities")[,2]

# Remove observations with missing target.

no.miss   <- na.omit(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
ROCR::plot(performance(pred, "prec", "rec"), col="#0000CCFF", lty=3, add=TRUE)


# Add a legend to the plot.

legend("bottomleft", c("ada","rf","ksvm"), col=rainbow(3, 1, .8), lty=1:3, title="Models", inset=c(0.05, 0.05))

# Add decorations to the plot.

title(main="Precision/Recall Plot  pca_addon_dataset.csv [test]",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
grid()

#============================================================
# Rattle timestamp: 2017-04-19 15:35:43 x86_64-w64-mingw32 

# Evaluate model performance. 

# Sensitivity/Specificity Plot: requires the ROCR package

library(ROCR)

# Generate Sensitivity/Specificity Plot for ada model on pca_addon_dataset.csv [test].

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="prob")[,2]

# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
ROCR::plot(performance(pred, "sens", "spec"), col="#CC0000FF", lty=1, add=FALSE)


# Generate a Lift Chart for the ada model on pca_addon_dataset.csv [train].

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="prob")[,2]

#In ROCR (1.0-3) plot does not obey the add command.
# Calling the function directly (.plot.performance) does work.

.plot.performance(performance(prediction(crs$pr, crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec),"sens", "spec"), col="#00CCCCFF", lty=2, add=TRUE)


# Add a legend to the plot.

legend("bottomleft", c("Test","Train"), col=rainbow(2, 1, .8), lty=1:2, title="ada", inset=c(0.05, 0.05))

# Add decorations to the plot.

title(main="Sensitivity/Specificity (tpr/tnr)  pca_addon_dataset.csv ",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
grid()

#============================================================
# Rattle timestamp: 2017-04-19 15:35:56 x86_64-w64-mingw32 

# Evaluate model performance. 

# ADA: Generate a Predicted v Observed plot for ada model on pca_addon_dataset.csv [test].

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="prob")[,2]

# Obtain the observed output for the dataset.

obs <- subset(crs$dataset[crs$test, c(crs$input, crs$target)], select=crs$target)

# Handle in case categoric target treated as numeric.

obs.rownames <- rownames(obs)
obs <- as.numeric(obs[[1]])
obs <- data.frame(male_dec=obs)
rownames(obs) <- obs.rownames

# Combine the observed values with the predicted.

fitpoints <- na.omit(cbind(obs, Predicted=crs$pr))

# Obtain the pseudo R2 - a correlation.

fitcorr <- format(cor(fitpoints[,1], fitpoints[,2])^2, digits=4)

# Plot settings for the true points and best fit.

op <- par(c(lty="solid", col="blue"))

# Display the observed (X) versus predicted (Y) points.

plot(jitter(fitpoints[[1]]), fitpoints[[2]], asp=1, xlab="male_dec (Jittered)", ylab="Predicted")

# Generate a simple linear fit between predicted and observed.

prline <- lm(fitpoints[,2] ~ fitpoints[,1])

# Add the linear fit to the plot.

abline(prline)

# Add a diagonal representing perfect correlation.

par(c(lty="dashed", col="black"))
abline(0, 1)

# Include a pseudo R-square on the plot

legend("bottomright",  sprintf(" Pseudo R-square=%s ", fitcorr),  bty="n")

# Add a title and grid to the plot.

title(main="Predicted vs. Observed
 Ada Boost Model
 pca_addon_dataset.csv [test]",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))
grid()

# Plot the error rate as we increase the number of trees.

plot(crs$ada)

# Plot the relative importance of the variables.

ada::varplot(crs$ada)

# Plot the relative importance of the variables.

ada::varplot(crs$ada)

# Plot the error rate as we increase the number of trees.

plot(crs$ada)

#============================================================
# Rattle timestamp: 2017-04-19 15:39:56 x86_64-w64-mingw32 

# Evaluate model performance. 

# Cost Curve: requires the ROCR package.

library(ROCR)

# Generate a Cost Curve for the Ada Boost model on pca_addon_dataset.csv [test].

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)], type="prob")[,2]
plot(0, 0, xlim=c(0, 1), ylim=c(0, 1), xlab="Probability cost function", ylab="Normalized expected cost")
lines(c(0,1),c(0,1))
lines(c(0,1),c(1,0))

# Remove observations with missing target.

no.miss   <- na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec)
miss.list <- attr(no.miss, "na.action")
attributes(no.miss) <- NULL

if (length(miss.list))
{
  pred <- prediction(crs$pr[-miss.list], no.miss)
} else
{
  pred <- prediction(crs$pr, no.miss)
}
perf1 <- performance(pred, "fpr", "fnr")
for (i in seq_along(perf1@x.values))
{
	for (j in seq_along(perf1@x.values[[i]]))
	{
		lines(c(0,1),c(perf1@y.values[[i]][j],
				perf1@x.values[[i]][j]),
				col=terrain.colors(10)[i],lty=3)
	}
}
perf<-performance(pred, "ecost")

# Bug in ROCR 1.0-3 does not obey the add command.
# Calling the function directly does work.

.plot.performance(perf, lwd=1.5, xlim=c(0,1), ylim=c(0,1), add=T)
op <- par(xpd=TRUE)
text(0, 1.07, "FPR")
text(1, 1.07, "FNR")
par(op)
text(0.12, 1, "Predict +ve")
text(0.88, 1, "Predict -ve")
title(main="Cost Curve Ada Boost pca_addon_dataset.csv [test]",
    sub=paste("Rattle", format(Sys.time(), "%Y-%b-%d %H:%M:%S"), Sys.info()["user"]))

#============================================================
# Rattle timestamp: 2017-04-19 15:40:49 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 15:55:51 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=500,
      mtry=8,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 19.06 secs

#============================================================
# Rattle timestamp: 2017-04-19 15:56:26 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 15:56:35 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 15:59:11 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=100,
      mtry=50,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 4.63 secs

#============================================================
# Rattle timestamp: 2017-04-19 15:59:21 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 15:59:25 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 15:59:44 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=100,
      mtry=30,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 4.17 secs

#============================================================
# Rattle timestamp: 2017-04-19 15:59:52 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:00:02 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=100,
      mtry=8,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 3.85 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:00:08 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:00:22 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=800,
      mtry=30,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 32.23 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:01:00 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:02:10 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:03:25 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 5.04 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:03:37 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:03:56 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:04:02 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="vanilladot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 6.36 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:04:14 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:04:56 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="vanilladot",
      gamma = 1, cost = 10,
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 6.19 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:05:07 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:05:14 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      gamma = 1, cost = 10,
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 4.81 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:05:22 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:05:57 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      gamma = 1, cost = 100,
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 4.73 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:06:05 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:06:37 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      C= 100,
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 6.05 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:06:49 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:06:57 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      C= 10,
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 5.46 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:07:07 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:07:17 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      C= .1,
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 5.58 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:07:27 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:07:56 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      C= 1, sigma=1,
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 4.95 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:08:08 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      sigma=1,
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 4.81 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:08:19 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:08:41 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:08:45 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:09:16 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(male_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      gamma=1,
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 4.74 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:10:55 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:11:21 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:12:01 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$male_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:12:59 x86_64-w64-mingw32 

# Note the user selections. 

# Build the training/validate/test datasets.

set.seed(crv$seed) 
crs$nobs <- nrow(crs$dataset) # 4105 observations 
crs$sample <- crs$train <- sample(nrow(crs$dataset), 0.7*crs$nobs) # 2873 observations
crs$validate <- sample(setdiff(seq_len(nrow(crs$dataset)), crs$train), 0.15*crs$nobs) # 615 observations
crs$test <- setdiff(setdiff(seq_len(nrow(crs$dataset)), crs$train), crs$validate) # 617 observations

# The following variable selections have been noted.

crs$input <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3",
     "f_self_perception_pca_vec_4", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "f_interests_pca_vec_3",
     "f_interests_pca_vec_4", "f_interests_pca_vec_5", "f_interests_pca_vec_6", "f_interests_pca_vec_7",
     "f_interests_pca_vec_8", "f_interests_pca_vec_9", "f_interests_pca_vec_10", "f_interests_pca_vec_11",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "m_interests_pca_vec_3", "m_interests_pca_vec_4", "m_interests_pca_vec_5", "m_interests_pca_vec_6",
     "m_interests_pca_vec_7", "m_interests_pca_vec_8", "m_interests_pca_vec_9", "m_interests_pca_vec_10",
     "m_interests_pca_vec_11", "TFC_samerace", "TFC_f_field_num", "TFC_f_race",
     "TFC_f_goal", "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num",
     "TFC_m_race", "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$numeric <- c("f_age", "f_imp_race", "f_imp_relig", "f_avg_attr",
     "f_avg_sinc", "f_avg_fun", "f_avg_intel", "f_avg_amb",
     "m_age", "m_imp_race", "m_imp_relig", "m_avg_attr",
     "m_avg_sinc", "m_avg_fun", "m_avg_intel", "m_avg_amb",
     "f_pref_pca_vec_1", "f_pref_pca_vec_2", "f_pref_pca_vec_3", "f_oppgender_perception_pca_vec_1",
     "f_oppgender_perception_pca_vec_2", "f_self_perception_pca_vec_1", "f_self_perception_pca_vec_2", "f_self_perception_pca_vec_3",
     "f_self_perception_pca_vec_4", "f_interests_pca_vec_1", "f_interests_pca_vec_2", "f_interests_pca_vec_3",
     "f_interests_pca_vec_4", "f_interests_pca_vec_5", "f_interests_pca_vec_6", "f_interests_pca_vec_7",
     "f_interests_pca_vec_8", "f_interests_pca_vec_9", "f_interests_pca_vec_10", "f_interests_pca_vec_11",
     "m_pref_pca_vec_1", "m_pref_pca_vec_2", "m_pref_pca_vec_3", "m_oppgender_perception_pca_vec_1",
     "m_oppgender_perception_pca_vec_2", "m_oppgender_perception_pca_vec_3", "m_self_perception_pca_vec_1", "m_self_perception_pca_vec_2",
     "m_self_perception_pca_vec_3", "m_self_perception_pca_vec_4", "m_interests_pca_vec_1", "m_interests_pca_vec_2",
     "m_interests_pca_vec_3", "m_interests_pca_vec_4", "m_interests_pca_vec_5", "m_interests_pca_vec_6",
     "m_interests_pca_vec_7", "m_interests_pca_vec_8", "m_interests_pca_vec_9", "m_interests_pca_vec_10",
     "m_interests_pca_vec_11")

crs$categoric <- c("TFC_samerace", "TFC_f_field_num", "TFC_f_race", "TFC_f_goal",
     "TFC_f_dat_freq", "TFC_f_out_freq", "TFC_m_field_num", "TFC_m_race",
     "TFC_m_goal", "TFC_m_dat_freq", "TFC_m_out_freq")

crs$target  <- "female_dec"
crs$risk    <- NULL
crs$ident   <- NULL
crs$ignore  <- c("X", "pair_id", "order", "interest_corr", "samerace", "match", "calls_from_female", "calls_from_male", "calls_to_female", "calls_to_male", "male_dec", "female_id", "f_rate_m_attr", "f_rate_m_sinc", "f_rate_m_intel", "f_rate_m_fun", "f_rate_m_amb", "f_rate_m_shar", "f_rate_m_like", "f_rate_m_prob", "f_rate_m_met_before", "f_est_matches", "f_field", "f_field_num", "f_race", "f_goal", "f_dat_freq", "f_out_freq", "f_career", "f_career_num", "f_like_sports", "f_like_tvsports", "f_like_exercise", "f_like_dining", "f_like_museums", "f_like_art", "f_like_hiking", "f_like_gaming", "f_like_clubbing", "f_like_reading", "f_like_tv", "f_like_theater", "f_like_movies", "f_like_concerts", "f_like_music", "f_like_shopping", "f_like_yoga", "f_exp_happy", "f_pref_attr", "f_pref_sinc", "f_pref_intel", "f_pref_fun", "f_pref_amb", "f_pref_shar", "f_genderpref_attr", "f_genderpref_sinc", "f_genderpref_intel", "f_genderpref_fun", "f_genderpref_amb", "f_genderpref_shar", "f_oppgender_pref_attr", "f_oppgender_pref_sinc", "f_oppgender_pref_intel", "f_oppgender_pref_fun", "f_oppgender_pref_amb", "f_oppgender_pref_shar", "f_rate_self_attr", "f_rate_self_sinc", "f_rate_self_fun", "f_rate_self_intel", "f_rate_self_amb", "f_avg_like", "male_id", "m_rate_f_attr", "m_rate_f_sinc", "m_rate_f_intel", "m_rate_f_fun", "m_rate_f_amb", "m_rate_f_shar", "m_rate_f_like", "m_rate_f_prob", "m_rate_f_met_before", "m_est_matches", "m_field", "m_field_num", "m_race", "m_goal", "m_dat_freq", "m_out_freq", "m_career", "m_career_num", "m_like_sports", "m_like_tvsports", "m_like_exercise", "m_like_dining", "m_like_museums", "m_like_art", "m_like_hiking", "m_like_gaming", "m_like_clubbing", "m_like_reading", "m_like_tv", "m_like_theater", "m_like_movies", "m_like_concerts", "m_like_music", "m_like_shopping", "m_like_yoga", "m_exp_happy", "m_pref_attr", "m_pref_sinc", "m_pref_intel", "m_pref_fun", "m_pref_amb", "m_pref_shar", "m_gender_pref_attr", "m_gender_pref_sinc", "m_gender_pref_intel", "m_gender_pref_fun", "m_gender_pref_amb", "m_gender_pref_shar", "m_opp_gender_pref_attr", "m_opp_gender_pref_sinc", "m_opp_gender_pref_intel", "m_opp_gender_pref_fun", "m_opp_gender_pref_amb", "m_opp_gender_pref_shar", "m_rate_self_attr", "m_rate_self_sinc", "m_rate_self_fun", "m_rate_self_intel", "m_rate_self_amb", "m_avg_like", "RRC_samerace", "RRC_f_field_num", "RRC_f_race", "RRC_f_goal", "RRC_f_dat_freq", "RRC_f_out_freq", "RRC_m_field_num", "RRC_m_race", "RRC_m_goal", "RRC_m_dat_freq", "RRC_m_out_freq")
crs$weights <- NULL

#============================================================
# Rattle timestamp: 2017-04-19 16:13:43 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(female_dec) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=800,
      mtry=30,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 32.60 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:14:21 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:15:01 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(female_dec) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=800,
      mtry=65,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 38.98 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:15:46 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:16:14 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(female_dec) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=5000,
      mtry=10,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 3.04 mins

#============================================================
# Rattle timestamp: 2017-04-19 16:20:49 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:21:34 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:21:40 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:22:02 x86_64-w64-mingw32 

# Random Forest 

# The 'randomForest' package provides the 'randomForest' function.

library(randomForest, quietly=TRUE)

# Build the Random Forest model.

set.seed(crv$seed)
crs$rf <- randomForest::randomForest(as.factor(female_dec) ~ .,
      data=crs$dataset[crs$sample,c(crs$input, crs$target)], 
      ntree=420,
      mtry=30,
      importance=TRUE,
      na.action=randomForest::na.roughfix,
      replace=FALSE)

# Generate textual output of 'Random Forest' model.

crs$rf

# The `pROC' package implements various AUC functions.

# Calculate the Area Under the Curve (AUC).

pROC::roc(crs$rf$y, as.numeric(crs$rf$predicted))

# Calculate the AUC Confidence Interval.

pROC::ci.auc(crs$rf$y, as.numeric(crs$rf$predicted))

# List the importance of the variables.

rn <- round(randomForest::importance(crs$rf), 2)
rn[order(rn[,3], decreasing=TRUE),]

# Time taken: 16.56 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:22:25 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:22:32 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:22:34 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:24:44 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.001000,
                                                 minsplit=20,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 2.22 mins

#============================================================
# Rattle timestamp: 2017-04-19 16:27:29 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$validate, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$validate, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

# Generate an Error Matrix for the Random Forest model.

# Obtain the response from the Random Forest model.

crs$pr <- predict(crs$rf, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:27:45 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:29:56 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.000500,
                                                 minsplit=20,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 2.23 mins

#============================================================
# Rattle timestamp: 2017-04-19 16:32:19 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:33:38 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=20,
                                                 cp=0.000500,
                                                 minsplit=10,
                                                 xval=10),
                    iter=500)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 3.14 mins

#============================================================
# Rattle timestamp: 2017-04-19 16:36:52 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:37:40 x86_64-w64-mingw32 

# Ada Boost 

# The `ada' package implements the boost algorithm.

# Build the Ada Boost model.

set.seed(crv$seed)
crs$ada <- ada::ada(female_dec ~ .,
                    data=crs$dataset[crs$train,c(crs$input, crs$target)],
                    control=rpart::rpart.control(maxdepth=30,
                                                 cp=0.000500,
                                                 minsplit=20,
                                                 xval=10),
                    iter=420)

# Print the results of the modelling.

print(crs$ada)
round(crs$ada$model$errs[crs$ada$iter,], 2)
cat('Variables actually used in tree construction:\n')
print(sort(names(listAdaVarsUsed(crs$ada))))
cat('\nFrequency of variables actually used:\n')
print(listAdaVarsUsed(crs$ada))

# Time taken: 2.20 mins

#============================================================
# Rattle timestamp: 2017-04-19 16:40:41 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:41:41 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the Ada Boost model.

# Obtain the response from the Ada Boost model.

crs$pr <- predict(crs$ada, newdata=crs$dataset[crs$test, c(crs$input, crs$target)])

# Generate the confusion matrix showing counts.

table(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(crs$dataset[crs$test, c(crs$input, crs$target)]$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:42:02 x86_64-w64-mingw32 

# Support vector machine. 

# The 'kernlab' package provides the 'ksvm' function.

library(kernlab, quietly=TRUE)

# Build a Support Vector Machine model.

set.seed(crv$seed)
crs$ksvm <- ksvm(as.factor(female_dec) ~ .,
      data=crs$dataset[crs$train,c(crs$input, crs$target)],
      kernel="rbfdot",
      prob.model=TRUE)

# Generate a textual view of the SVM model.

crs$ksvm

# Time taken: 4.61 secs

#============================================================
# Rattle timestamp: 2017-04-19 16:42:15 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$validate, c(crs$input, crs$target)])$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))

#============================================================
# Rattle timestamp: 2017-04-19 16:42:43 x86_64-w64-mingw32 

# Evaluate model performance. 

# Generate an Error Matrix for the SVM model.

# Obtain the response from the SVM model.

crs$pr <- kernlab::predict(crs$ksvm, newdata=na.omit(crs$dataset[crs$test, c(crs$input, crs$target)]))

# Generate the confusion matrix showing counts.

table(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$female_dec, crs$pr,
        useNA="ifany",
        dnn=c("Actual", "Predicted"))

# Generate the confusion matrix showing proportions.

pcme <- function(actual, cl)
{
  x <- table(actual, cl)
  nc <- nrow(x) # Number of classes.
  nv <- length(actual) - sum(is.na(actual) | is.na(cl)) # Number of values.
  tbl <- cbind(x/nv,
               Error=sapply(1:nc,
                 function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}
per <- pcme(na.omit(crs$dataset[crs$test, c(crs$input, crs$target)])$female_dec, crs$pr)
round(per, 2)

# Calculate the overall error percentage.

cat(100*round(1-sum(diag(per), na.rm=TRUE), 2))

# Calculate the averaged class error percentage.

cat(100*round(mean(per[,"Error"], na.rm=TRUE), 2))
